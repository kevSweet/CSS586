{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "illegal-maldives",
   "metadata": {},
   "source": [
    "# Data Loading and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "anticipated-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for generating category-name mapping for anchors\n",
    "\n",
    "def map_array_values(array, value_map):\n",
    "    # value map must be { src : target }\n",
    "    ret = array.copy()\n",
    "    for src, target in value_map.items():\n",
    "        ret[ret == src] = target\n",
    "    return ret\n",
    "\n",
    "def replace_binary_values(array, values):\n",
    "    return map_array_values(array, {'0': values[0], '1': values[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "thick-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "transforms = {\n",
    "            5: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            6: lambda x: replace_binary_values(x, ['New Vehicle', 'Used Vehicle']),\n",
    "            7: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            10: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            11: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            12: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            13: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            14: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            15: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            16: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            17: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            18: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            19: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            20: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            21: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            22: lambda x: replace_binary_values(x, ['Not Defaulted', 'Defaulted']),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "prescribed-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset using XAI data loader. This will 50/50 class balance the dataset by downsampling,\n",
    "#create mappings for column categories to explainable names and 80/20 split into train/test\n",
    "dataset = utils.load_csv_dataset('preprocessed.csv', 22, delimiter=',',\n",
    "                 categorical_features=[5,6,7,10,11,12,13,14,15,16,17,18,19,20,21],\n",
    "                 feature_transformations=transforms, discretize=False, balance=True, fill_na=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "considered-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410900,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "personal-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add axis for skorch compatability\n",
    "dataset.labels_train = dataset.labels_train[:, np.newaxis]\n",
    "dataset.labels_test = dataset.labels_test[:, np.newaxis]\n",
    "\n",
    "# Cast to floats for skorch compatability\n",
    "dataset.train = dataset.train.astype(np.float32)\n",
    "dataset.labels_train = dataset.labels_train.astype(np.float32)\n",
    "dataset.test = dataset.test.astype(np.float32)\n",
    "dataset.labels_test = dataset.labels_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "prescription-final",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410900, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sufficient-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training and test data using min-max normalization \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "dataset.train = scaler.fit_transform(dataset.train)\n",
    "dataset.test = scaler.transform(dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-piano",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-information",
   "metadata": {},
   "source": [
    "Now that the data is prepared, we will use grid search to find good parameters for a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "toxic-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "modern-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network module that can accept params we will use in our grid search\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# modules: list of (nn activation funcs or layers) see https://pytorch.org/docs/stable/nn.html\n",
    "# modules must retain proper input and output shape sequentially\n",
    "class NetModule(nn.Module):\n",
    "    def __init__(self, net_modules):\n",
    "        super(NetModule, self).__init__()\n",
    "        self.net_modules = nn.Sequential(*net_modules)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net_modules(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "specific-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set internal dimensions\n",
    "input_dim = dataset.train.shape[1]\n",
    "output_dim = 1 # binary classification, default or no default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "failing-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "included_modules = []\n",
    "\n",
    "# Search Sigmoid activation with different neurons in hidden layer\n",
    "included_modules.append([nn.Linear(input_dim, 50),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(50, output_dim)\n",
    "                          ])\n",
    "\n",
    "# Search Sigmoid activation with different neurons in hidden layer\n",
    "included_modules.append([nn.Linear(input_dim, 50),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(50, 25),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(25, output_dim)\n",
    "                          ])\n",
    "\n",
    "\n",
    "# Search Sigmoid activation with different neurons in hidden layer\n",
    "included_modules.append([nn.Linear(input_dim, 75),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(75, 50),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(50, output_dim)\n",
    "                          ])\n",
    "\n",
    "# Number of architectures\n",
    "print(len(included_modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "improved-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Create sklearn scorer for use in architecture search\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "early_stop = EarlyStopping(patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "informative-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize skorch NN classifier with default params\n",
    "net = NeuralNetClassifier(\n",
    "    NetModule,\n",
    "    criterion= nn.BCEWithLogitsLoss(),\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__momentum=0.95,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size = len(dataset.train), \n",
    "    callbacks=[early_stop],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "peripheral-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV 1/2; 1/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7130\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m0.6918\u001b[0m  4.2420\n",
      "      2        \u001b[36m0.6918\u001b[0m       \u001b[32m0.5004\u001b[0m        0.6970  2.4060\n",
      "      3        0.6971       0.5004        0.7115  2.4900\n",
      "      4        0.7116       0.5004        0.6986  2.4820\n",
      "      5        0.6987       \u001b[32m0.6244\u001b[0m        \u001b[35m0.6863\u001b[0m  2.4751\n",
      "      6        \u001b[36m0.6864\u001b[0m       0.4996        0.6982  2.4790\n",
      "      7        0.6983       0.4996        0.7005  2.3680\n",
      "      8        0.7007       0.4997        \u001b[35m0.6840\u001b[0m  2.4301\n",
      "      9        \u001b[36m0.6842\u001b[0m       0.5004        \u001b[35m0.6822\u001b[0m  2.6922\n",
      "     10        \u001b[36m0.6824\u001b[0m       0.5004        0.6918  2.5255\n",
      "     11        0.6920       0.5004        0.6838  2.4760\n",
      "     12        0.6840       \u001b[32m0.7291\u001b[0m        \u001b[35m0.6709\u001b[0m  2.4610\n",
      "     13        \u001b[36m0.6713\u001b[0m       0.5037        0.6752  2.3950\n",
      "     14        0.6755       0.4998        0.6772  2.4630\n",
      "     15        0.6777       0.6286        \u001b[35m0.6641\u001b[0m  2.4802\n",
      "     16        \u001b[36m0.6646\u001b[0m       0.6591        \u001b[35m0.6572\u001b[0m  2.4676\n",
      "     17        \u001b[36m0.6577\u001b[0m       0.5006        0.6612  2.3790\n",
      "     18        0.6617       0.5092        \u001b[35m0.6548\u001b[0m  2.3596\n",
      "     19        \u001b[36m0.6554\u001b[0m       \u001b[32m0.7325\u001b[0m        \u001b[35m0.6414\u001b[0m  2.3950\n",
      "     20        \u001b[36m0.6421\u001b[0m       0.7091        \u001b[35m0.6387\u001b[0m  2.4350\n",
      "     21        \u001b[36m0.6396\u001b[0m       0.6727        \u001b[35m0.6378\u001b[0m  2.4380\n",
      "     22        \u001b[36m0.6388\u001b[0m       0.7217        \u001b[35m0.6256\u001b[0m  2.4318\n",
      "     23        \u001b[36m0.6266\u001b[0m       \u001b[32m0.7479\u001b[0m        \u001b[35m0.6143\u001b[0m  2.3870\n",
      "     24        \u001b[36m0.6155\u001b[0m       0.6747        \u001b[35m0.6119\u001b[0m  2.4620\n",
      "     25        \u001b[36m0.6131\u001b[0m       0.6784        \u001b[35m0.6045\u001b[0m  2.4480\n",
      "     26        \u001b[36m0.6059\u001b[0m       0.7455        \u001b[35m0.5902\u001b[0m  2.4490\n",
      "     27        \u001b[36m0.5917\u001b[0m       0.7444        \u001b[35m0.5819\u001b[0m  2.4060\n",
      "     28        \u001b[36m0.5837\u001b[0m       0.7378        \u001b[35m0.5775\u001b[0m  2.3798\n",
      "     29        \u001b[36m0.5795\u001b[0m       0.7456        \u001b[35m0.5662\u001b[0m  2.3570\n",
      "     30        \u001b[36m0.5684\u001b[0m       \u001b[32m0.7514\u001b[0m        \u001b[35m0.5533\u001b[0m  2.4280\n",
      "     31        \u001b[36m0.5556\u001b[0m       0.7480        \u001b[35m0.5469\u001b[0m  2.4630\n",
      "     32        \u001b[36m0.5493\u001b[0m       0.7453        \u001b[35m0.5407\u001b[0m  2.4495\n",
      "     33        \u001b[36m0.5432\u001b[0m       \u001b[32m0.7536\u001b[0m        \u001b[35m0.5292\u001b[0m  2.4240\n",
      "     34        \u001b[36m0.5320\u001b[0m       \u001b[32m0.7557\u001b[0m        \u001b[35m0.5199\u001b[0m  2.4292\n",
      "     35        \u001b[36m0.5230\u001b[0m       0.7540        \u001b[35m0.5156\u001b[0m  2.4600\n",
      "     36        \u001b[36m0.5190\u001b[0m       0.7556        \u001b[35m0.5094\u001b[0m  2.4180\n",
      "     37        \u001b[36m0.5130\u001b[0m       \u001b[32m0.7602\u001b[0m        \u001b[35m0.5002\u001b[0m  2.5420\n",
      "     38        \u001b[36m0.5039\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m0.4938\u001b[0m  2.3595\n",
      "     39        \u001b[36m0.4975\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.4907\u001b[0m  2.3740\n",
      "     40        \u001b[36m0.4944\u001b[0m       \u001b[32m0.7661\u001b[0m        \u001b[35m0.4854\u001b[0m  2.4500\n",
      "     41        \u001b[36m0.4893\u001b[0m       \u001b[32m0.7711\u001b[0m        \u001b[35m0.4781\u001b[0m  2.4679\n",
      "     42        \u001b[36m0.4822\u001b[0m       \u001b[32m0.7757\u001b[0m        \u001b[35m0.4733\u001b[0m  2.4590\n",
      "     43        \u001b[36m0.4777\u001b[0m       \u001b[32m0.7793\u001b[0m        \u001b[35m0.4704\u001b[0m  2.3930\n",
      "     44        \u001b[36m0.4750\u001b[0m       \u001b[32m0.7843\u001b[0m        \u001b[35m0.4657\u001b[0m  2.4870\n",
      "     45        \u001b[36m0.4703\u001b[0m       \u001b[32m0.7893\u001b[0m        \u001b[35m0.4594\u001b[0m  2.4041\n",
      "     46        \u001b[36m0.4639\u001b[0m       \u001b[32m0.7916\u001b[0m        \u001b[35m0.4551\u001b[0m  2.4917\n",
      "     47        \u001b[36m0.4594\u001b[0m       \u001b[32m0.7927\u001b[0m        \u001b[35m0.4522\u001b[0m  2.3990\n",
      "     48        \u001b[36m0.4564\u001b[0m       \u001b[32m0.7979\u001b[0m        \u001b[35m0.4475\u001b[0m  2.3571\n",
      "     49        \u001b[36m0.4517\u001b[0m       \u001b[32m0.8065\u001b[0m        \u001b[35m0.4415\u001b[0m  2.3940\n",
      "     50        \u001b[36m0.4458\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.4370\u001b[0m  2.5100\n",
      "     51        \u001b[36m0.4415\u001b[0m       \u001b[32m0.8144\u001b[0m        \u001b[35m0.4338\u001b[0m  2.4940\n",
      "     52        \u001b[36m0.4384\u001b[0m       \u001b[32m0.8179\u001b[0m        \u001b[35m0.4296\u001b[0m  2.5650\n",
      "     53        \u001b[36m0.4341\u001b[0m       \u001b[32m0.8223\u001b[0m        \u001b[35m0.4247\u001b[0m  2.4090\n",
      "     54        \u001b[36m0.4290\u001b[0m       \u001b[32m0.8254\u001b[0m        \u001b[35m0.4212\u001b[0m  2.5290\n",
      "     55        \u001b[36m0.4252\u001b[0m       \u001b[32m0.8274\u001b[0m        \u001b[35m0.4189\u001b[0m  2.5130\n",
      "     56        \u001b[36m0.4227\u001b[0m       \u001b[32m0.8303\u001b[0m        \u001b[35m0.4158\u001b[0m  2.4660\n",
      "     57        \u001b[36m0.4195\u001b[0m       \u001b[32m0.8334\u001b[0m        \u001b[35m0.4119\u001b[0m  2.3906\n",
      "     58        \u001b[36m0.4157\u001b[0m       \u001b[32m0.8349\u001b[0m        \u001b[35m0.4092\u001b[0m  2.4147\n",
      "     59        \u001b[36m0.4131\u001b[0m       \u001b[32m0.8356\u001b[0m        \u001b[35m0.4077\u001b[0m  2.3840\n",
      "     60        \u001b[36m0.4116\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4058\u001b[0m  2.5010\n",
      "     61        \u001b[36m0.4098\u001b[0m       \u001b[32m0.8372\u001b[0m        \u001b[35m0.4037\u001b[0m  2.4419\n",
      "     62        \u001b[36m0.4075\u001b[0m       \u001b[32m0.8373\u001b[0m        \u001b[35m0.4024\u001b[0m  2.4950\n",
      "     63        \u001b[36m0.4061\u001b[0m       0.8362        \u001b[35m0.4022\u001b[0m  2.3790\n",
      "     64        \u001b[36m0.4056\u001b[0m       0.8360        \u001b[35m0.4014\u001b[0m  2.4590\n",
      "     65        \u001b[36m0.4049\u001b[0m       0.8365        \u001b[35m0.4000\u001b[0m  2.4490\n",
      "     66        \u001b[36m0.4036\u001b[0m       0.8372        \u001b[35m0.3991\u001b[0m  2.5230\n",
      "     67        \u001b[36m0.4029\u001b[0m       0.8369        \u001b[35m0.3990\u001b[0m  2.3990\n",
      "     68        0.4029       0.8370        \u001b[35m0.3987\u001b[0m  2.3780\n",
      "     69        \u001b[36m0.4027\u001b[0m       0.8364        \u001b[35m0.3979\u001b[0m  2.4166\n",
      "     70        \u001b[36m0.4020\u001b[0m       0.8353        \u001b[35m0.3975\u001b[0m  2.4480\n",
      "     71        \u001b[36m0.4015\u001b[0m       0.8341        0.3976  2.5123\n",
      "     72        0.4017       0.8333        0.3975  2.4840\n",
      "     73        0.4016       0.8336        \u001b[35m0.3968\u001b[0m  2.4470\n",
      "     74        \u001b[36m0.4011\u001b[0m       0.8350        \u001b[35m0.3961\u001b[0m  2.5170\n",
      "     75        \u001b[36m0.4006\u001b[0m       0.8352        \u001b[35m0.3958\u001b[0m  2.4730\n",
      "     76        0.4006       0.8355        \u001b[35m0.3956\u001b[0m  2.5300\n",
      "     77        0.4006       0.8348        \u001b[35m0.3951\u001b[0m  2.4200\n",
      "     78        \u001b[36m0.4002\u001b[0m       0.8343        \u001b[35m0.3946\u001b[0m  2.4340\n",
      "     79        \u001b[36m0.3997\u001b[0m       0.8342        \u001b[35m0.3944\u001b[0m  2.4240\n",
      "     80        \u001b[36m0.3997\u001b[0m       0.8341        \u001b[35m0.3943\u001b[0m  2.4560\n",
      "     81        0.3997       0.8342        \u001b[35m0.3939\u001b[0m  2.4723\n",
      "     82        \u001b[36m0.3993\u001b[0m       0.8351        \u001b[35m0.3932\u001b[0m  2.4676\n",
      "     83        \u001b[36m0.3989\u001b[0m       0.8354        \u001b[35m0.3927\u001b[0m  2.4010\n",
      "     84        \u001b[36m0.3987\u001b[0m       0.8362        \u001b[35m0.3925\u001b[0m  2.4530\n",
      "     85        \u001b[36m0.3986\u001b[0m       0.8364        \u001b[35m0.3920\u001b[0m  2.4730\n",
      "     86        \u001b[36m0.3983\u001b[0m       0.8362        \u001b[35m0.3915\u001b[0m  2.4260\n",
      "     87        \u001b[36m0.3978\u001b[0m       0.8358        \u001b[35m0.3911\u001b[0m  2.3810\n",
      "     88        \u001b[36m0.3974\u001b[0m       0.8356        \u001b[35m0.3908\u001b[0m  2.4370\n",
      "     89        \u001b[36m0.3972\u001b[0m       0.8357        \u001b[35m0.3904\u001b[0m  2.4100\n",
      "     90        \u001b[36m0.3969\u001b[0m       0.8363        \u001b[35m0.3897\u001b[0m  2.4740\n",
      "     91        \u001b[36m0.3963\u001b[0m       \u001b[32m0.8374\u001b[0m        \u001b[35m0.3890\u001b[0m  2.4650\n",
      "     92        \u001b[36m0.3957\u001b[0m       \u001b[32m0.8381\u001b[0m        \u001b[35m0.3884\u001b[0m  2.5130\n",
      "     93        \u001b[36m0.3953\u001b[0m       \u001b[32m0.8386\u001b[0m        \u001b[35m0.3879\u001b[0m  2.5457\n",
      "     94        \u001b[36m0.3949\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m0.3873\u001b[0m  2.4860\n",
      "     95        \u001b[36m0.3942\u001b[0m       0.8387        \u001b[35m0.3866\u001b[0m  2.4750\n",
      "     96        \u001b[36m0.3936\u001b[0m       0.8386        \u001b[35m0.3861\u001b[0m  2.4370\n",
      "     97        \u001b[36m0.3930\u001b[0m       0.8383        \u001b[35m0.3857\u001b[0m  2.4160\n",
      "     98        \u001b[36m0.3926\u001b[0m       \u001b[32m0.8388\u001b[0m        \u001b[35m0.3851\u001b[0m  2.4080\n",
      "     99        \u001b[36m0.3920\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.3844\u001b[0m  2.3920\n",
      "    100        \u001b[36m0.3913\u001b[0m       \u001b[32m0.8399\u001b[0m        \u001b[35m0.3838\u001b[0m  2.4970\n",
      "[CV 1/2; 1/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]; total time= 4.2min\n",
      "[CV 2/2; 1/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7129\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m0.6919\u001b[0m  2.3140\n",
      "      2        \u001b[36m0.6918\u001b[0m       \u001b[32m0.5004\u001b[0m        0.6971  2.5210\n",
      "      3        0.6970       0.5004        0.7116  2.6570\n",
      "      4        0.7115       0.5004        0.6988  2.5610\n",
      "      5        0.6986       \u001b[32m0.6215\u001b[0m        \u001b[35m0.6865\u001b[0m  2.6273\n",
      "      6        \u001b[36m0.6863\u001b[0m       0.4996        0.6984  2.7930\n",
      "      7        0.6982       0.4996        0.7008  2.7150\n",
      "      8        0.7005       0.4997        \u001b[35m0.6843\u001b[0m  2.4670\n",
      "      9        \u001b[36m0.6840\u001b[0m       0.5004        \u001b[35m0.6824\u001b[0m  2.5080\n",
      "     10        \u001b[36m0.6822\u001b[0m       0.5004        0.6920  2.7229\n",
      "     11        0.6917       0.5004        0.6840  2.4500\n",
      "     12        0.6837       \u001b[32m0.7221\u001b[0m        \u001b[35m0.6713\u001b[0m  2.5070\n",
      "     13        \u001b[36m0.6709\u001b[0m       0.5035        0.6756  2.5080\n",
      "     14        0.6751       0.5000        0.6778  2.5340\n",
      "     15        0.6772       0.6282        \u001b[35m0.6646\u001b[0m  2.5360\n",
      "     16        \u001b[36m0.6640\u001b[0m       0.6553        \u001b[35m0.6577\u001b[0m  2.4770\n",
      "     17        \u001b[36m0.6571\u001b[0m       0.5010        0.6616  2.5310\n",
      "     18        0.6610       0.5113        \u001b[35m0.6554\u001b[0m  2.4730\n",
      "     19        \u001b[36m0.6546\u001b[0m       \u001b[32m0.7249\u001b[0m        \u001b[35m0.6421\u001b[0m  2.4635\n",
      "     20        \u001b[36m0.6412\u001b[0m       0.7064        \u001b[35m0.6396\u001b[0m  2.5310\n",
      "     21        \u001b[36m0.6385\u001b[0m       0.6712        \u001b[35m0.6389\u001b[0m  2.4965\n",
      "     22        \u001b[36m0.6376\u001b[0m       0.7171        \u001b[35m0.6267\u001b[0m  2.4970\n",
      "     23        \u001b[36m0.6253\u001b[0m       \u001b[32m0.7403\u001b[0m        \u001b[35m0.6154\u001b[0m  2.4690\n",
      "     24        \u001b[36m0.6140\u001b[0m       0.6707        \u001b[35m0.6129\u001b[0m  2.6715\n",
      "     25        \u001b[36m0.6115\u001b[0m       0.6735        \u001b[35m0.6057\u001b[0m  2.4670\n",
      "     26        \u001b[36m0.6041\u001b[0m       0.7380        \u001b[35m0.5917\u001b[0m  2.4780\n",
      "     27        \u001b[36m0.5899\u001b[0m       0.7367        \u001b[35m0.5839\u001b[0m  2.5130\n",
      "     28        \u001b[36m0.5817\u001b[0m       0.7324        \u001b[35m0.5799\u001b[0m  2.4910\n",
      "     29        \u001b[36m0.5775\u001b[0m       0.7394        \u001b[35m0.5689\u001b[0m  2.5108\n",
      "     30        \u001b[36m0.5663\u001b[0m       \u001b[32m0.7437\u001b[0m        \u001b[35m0.5559\u001b[0m  2.4780\n",
      "     31        \u001b[36m0.5534\u001b[0m       0.7411        \u001b[35m0.5496\u001b[0m  2.4450\n",
      "     32        \u001b[36m0.5471\u001b[0m       0.7385        \u001b[35m0.5435\u001b[0m  2.5110\n",
      "     33        \u001b[36m0.5410\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m0.5326\u001b[0m  2.6395\n",
      "     34        \u001b[36m0.5299\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.5241\u001b[0m  2.5311\n",
      "     35        \u001b[36m0.5209\u001b[0m       0.7459        \u001b[35m0.5205\u001b[0m  2.7040\n",
      "     36        \u001b[36m0.5169\u001b[0m       \u001b[32m0.7484\u001b[0m        \u001b[35m0.5149\u001b[0m  2.5000\n",
      "     37        \u001b[36m0.5111\u001b[0m       \u001b[32m0.7526\u001b[0m        \u001b[35m0.5057\u001b[0m  2.4796\n",
      "     38        \u001b[36m0.5021\u001b[0m       \u001b[32m0.7552\u001b[0m        \u001b[35m0.4990\u001b[0m  2.6062\n",
      "     39        \u001b[36m0.4957\u001b[0m       \u001b[32m0.7561\u001b[0m        \u001b[35m0.4958\u001b[0m  2.5160\n",
      "     40        \u001b[36m0.4926\u001b[0m       \u001b[32m0.7588\u001b[0m        \u001b[35m0.4908\u001b[0m  2.5320\n",
      "     41        \u001b[36m0.4877\u001b[0m       \u001b[32m0.7641\u001b[0m        \u001b[35m0.4840\u001b[0m  2.5660\n",
      "     42        \u001b[36m0.4808\u001b[0m       \u001b[32m0.7684\u001b[0m        \u001b[35m0.4796\u001b[0m  2.4730\n",
      "     43        \u001b[36m0.4762\u001b[0m       \u001b[32m0.7727\u001b[0m        \u001b[35m0.4771\u001b[0m  2.4479\n",
      "     44        \u001b[36m0.4735\u001b[0m       \u001b[32m0.7776\u001b[0m        \u001b[35m0.4724\u001b[0m  2.4490\n",
      "     45        \u001b[36m0.4689\u001b[0m       \u001b[32m0.7832\u001b[0m        \u001b[35m0.4657\u001b[0m  2.4510\n",
      "     46        \u001b[36m0.4626\u001b[0m       \u001b[32m0.7842\u001b[0m        \u001b[35m0.4606\u001b[0m  2.4700\n",
      "     47        \u001b[36m0.4580\u001b[0m       \u001b[32m0.7859\u001b[0m        \u001b[35m0.4571\u001b[0m  2.4640\n",
      "     48        \u001b[36m0.4549\u001b[0m       \u001b[32m0.7912\u001b[0m        \u001b[35m0.4524\u001b[0m  2.4450\n",
      "     49        \u001b[36m0.4504\u001b[0m       \u001b[32m0.8000\u001b[0m        \u001b[35m0.4465\u001b[0m  2.4770\n",
      "     50        \u001b[36m0.4445\u001b[0m       \u001b[32m0.8064\u001b[0m        \u001b[35m0.4420\u001b[0m  2.4700\n",
      "     51        \u001b[36m0.4400\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m0.4388\u001b[0m  2.4260\n",
      "     52        \u001b[36m0.4369\u001b[0m       \u001b[32m0.8136\u001b[0m        \u001b[35m0.4344\u001b[0m  2.4785\n",
      "     53        \u001b[36m0.4327\u001b[0m       \u001b[32m0.8175\u001b[0m        \u001b[35m0.4289\u001b[0m  2.4986\n",
      "     54        \u001b[36m0.4276\u001b[0m       \u001b[32m0.8220\u001b[0m        \u001b[35m0.4244\u001b[0m  2.4700\n",
      "     55        \u001b[36m0.4237\u001b[0m       \u001b[32m0.8251\u001b[0m        \u001b[35m0.4215\u001b[0m  2.4850\n",
      "     56        \u001b[36m0.4212\u001b[0m       \u001b[32m0.8274\u001b[0m        \u001b[35m0.4182\u001b[0m  2.4610\n",
      "     57        \u001b[36m0.4181\u001b[0m       \u001b[32m0.8308\u001b[0m        \u001b[35m0.4143\u001b[0m  2.4390\n",
      "     58        \u001b[36m0.4143\u001b[0m       \u001b[32m0.8322\u001b[0m        \u001b[35m0.4116\u001b[0m  2.4620\n",
      "     59        \u001b[36m0.4116\u001b[0m       \u001b[32m0.8330\u001b[0m        \u001b[35m0.4102\u001b[0m  2.4785\n",
      "     60        \u001b[36m0.4102\u001b[0m       \u001b[32m0.8342\u001b[0m        \u001b[35m0.4083\u001b[0m  2.4940\n",
      "     61        \u001b[36m0.4084\u001b[0m       \u001b[32m0.8357\u001b[0m        \u001b[35m0.4057\u001b[0m  2.5016\n",
      "     62        \u001b[36m0.4061\u001b[0m       \u001b[32m0.8358\u001b[0m        \u001b[35m0.4038\u001b[0m  2.5998\n",
      "     63        \u001b[36m0.4047\u001b[0m       0.8352        \u001b[35m0.4031\u001b[0m  2.5280\n",
      "     64        \u001b[36m0.4042\u001b[0m       0.8341        \u001b[35m0.4023\u001b[0m  2.5550\n",
      "     65        \u001b[36m0.4036\u001b[0m       0.8349        \u001b[35m0.4011\u001b[0m  2.5569\n",
      "     66        \u001b[36m0.4023\u001b[0m       0.8353        \u001b[35m0.4004\u001b[0m  2.4949\n",
      "     67        \u001b[36m0.4016\u001b[0m       0.8350        0.4005  2.5436\n",
      "     68        0.4016       0.8350        \u001b[35m0.4004\u001b[0m  2.5021\n",
      "     69        \u001b[36m0.4015\u001b[0m       0.8346        \u001b[35m0.3995\u001b[0m  2.8122\n",
      "     70        \u001b[36m0.4008\u001b[0m       0.8339        \u001b[35m0.3988\u001b[0m  2.3750\n",
      "     71        \u001b[36m0.4003\u001b[0m       0.8328        \u001b[35m0.3987\u001b[0m  2.4680\n",
      "     72        0.4003       0.8317        \u001b[35m0.3986\u001b[0m  2.6320\n",
      "     73        0.4003       0.8326        \u001b[35m0.3982\u001b[0m  2.4930\n",
      "     74        \u001b[36m0.3998\u001b[0m       0.8333        \u001b[35m0.3978\u001b[0m  2.4640\n",
      "     75        \u001b[36m0.3993\u001b[0m       0.8331        0.3979  2.4655\n",
      "     76        \u001b[36m0.3992\u001b[0m       0.8328        0.3980  2.6879\n",
      "     77        0.3993       0.8328        \u001b[35m0.3976\u001b[0m  2.5166\n",
      "     78        \u001b[36m0.3989\u001b[0m       0.8322        \u001b[35m0.3970\u001b[0m  2.4850\n",
      "     79        \u001b[36m0.3983\u001b[0m       0.8318        \u001b[35m0.3967\u001b[0m  2.4800\n",
      "     80        \u001b[36m0.3982\u001b[0m       0.8317        \u001b[35m0.3967\u001b[0m  2.4950\n",
      "     81        \u001b[36m0.3982\u001b[0m       0.8316        \u001b[35m0.3964\u001b[0m  2.5210\n",
      "     82        \u001b[36m0.3979\u001b[0m       0.8319        \u001b[35m0.3961\u001b[0m  2.7651\n",
      "     83        \u001b[36m0.3974\u001b[0m       0.8323        \u001b[35m0.3959\u001b[0m  2.5220\n",
      "     84        \u001b[36m0.3971\u001b[0m       0.8326        0.3960  2.4420\n",
      "     85        \u001b[36m0.3970\u001b[0m       0.8329        \u001b[35m0.3957\u001b[0m  2.5180\n",
      "     86        \u001b[36m0.3967\u001b[0m       0.8329        \u001b[35m0.3952\u001b[0m  2.4840\n",
      "     87        \u001b[36m0.3962\u001b[0m       0.8326        \u001b[35m0.3947\u001b[0m  2.4860\n",
      "     88        \u001b[36m0.3958\u001b[0m       0.8321        \u001b[35m0.3943\u001b[0m  2.7807\n",
      "     89        \u001b[36m0.3955\u001b[0m       0.8322        \u001b[35m0.3940\u001b[0m  2.5540\n",
      "     90        \u001b[36m0.3952\u001b[0m       0.8327        \u001b[35m0.3934\u001b[0m  2.5030\n",
      "     91        \u001b[36m0.3946\u001b[0m       0.8338        \u001b[35m0.3929\u001b[0m  2.4780\n",
      "     92        \u001b[36m0.3940\u001b[0m       0.8342        \u001b[35m0.3925\u001b[0m  2.4730\n",
      "     93        \u001b[36m0.3936\u001b[0m       0.8344        \u001b[35m0.3921\u001b[0m  2.5260\n",
      "     94        \u001b[36m0.3931\u001b[0m       0.8346        \u001b[35m0.3915\u001b[0m  2.4770\n",
      "     95        \u001b[36m0.3925\u001b[0m       0.8346        \u001b[35m0.3908\u001b[0m  2.5350\n",
      "     96        \u001b[36m0.3918\u001b[0m       0.8348        \u001b[35m0.3901\u001b[0m  2.4840\n",
      "     97        \u001b[36m0.3912\u001b[0m       0.8344        \u001b[35m0.3895\u001b[0m  2.5323\n",
      "     98        \u001b[36m0.3908\u001b[0m       0.8346        \u001b[35m0.3889\u001b[0m  2.5190\n",
      "     99        \u001b[36m0.3902\u001b[0m       0.8350        \u001b[35m0.3883\u001b[0m  2.5290\n",
      "    100        \u001b[36m0.3896\u001b[0m       \u001b[32m0.8358\u001b[0m        \u001b[35m0.3878\u001b[0m  2.4360\n",
      "[CV 2/2; 1/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]; total time= 4.3min\n",
      "[CV 1/2; 2/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=25, bias=True), ReLU(), Linear(in_features=25, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7087\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m0.7030\u001b[0m  2.2450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.7030\u001b[0m       0.4996        \u001b[35m0.6969\u001b[0m  2.5130\n",
      "      3        \u001b[36m0.6969\u001b[0m       0.4996        \u001b[35m0.6937\u001b[0m  2.5280\n",
      "      4        \u001b[36m0.6937\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m0.6932\u001b[0m  2.4690\n",
      "      5        \u001b[36m0.6932\u001b[0m       0.5004        0.6944  2.4770\n",
      "      6        0.6944       0.5004        0.6962  2.5040\n",
      "      7        0.6962       0.5004        0.6975  2.5530\n",
      "      8        0.6975       0.5004        0.6978  2.6041\n",
      "      9        0.6979       0.5004        0.6971  2.5140\n",
      "     10        0.6971       0.5004        0.6958  2.4790\n",
      "Stopping since valid_loss has not improved in the last 7 epochs.\n",
      "[CV 1/2; 2/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=25, bias=True), ReLU(), Linear(in_features=25, out_features=1, bias=True)]; total time=  30.5s\n",
      "[CV 2/2; 2/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=25, bias=True), ReLU(), Linear(in_features=25, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7087\u001b[0m       \u001b[32m0.4996\u001b[0m        \u001b[35m0.7029\u001b[0m  2.2770\n",
      "      2        \u001b[36m0.7030\u001b[0m       0.4996        \u001b[35m0.6969\u001b[0m  2.4320\n",
      "      3        \u001b[36m0.6969\u001b[0m       0.4996        \u001b[35m0.6937\u001b[0m  2.4390\n",
      "      4        \u001b[36m0.6937\u001b[0m       \u001b[32m0.5004\u001b[0m        \u001b[35m0.6932\u001b[0m  2.4592\n",
      "      5        \u001b[36m0.6932\u001b[0m       0.5004        0.6944  2.4750\n",
      "      6        0.6944       0.5004        0.6963  2.4580\n",
      "      7        0.6962       0.5004        0.6976  2.4680\n",
      "      8        0.6975       0.5004        0.6979  2.4531\n",
      "      9        0.6979       0.5004        0.6972  2.4702\n",
      "     10        0.6971       0.5004        0.6958  2.4947\n",
      "Stopping since valid_loss has not improved in the last 7 epochs.\n",
      "[CV 2/2; 2/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=25, bias=True), ReLU(), Linear(in_features=25, out_features=1, bias=True)]; total time=  29.9s\n",
      "[CV 1/2; 3/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=75, bias=True), Sigmoid(), Linear(in_features=75, out_features=50, bias=True), ReLU(), Linear(in_features=50, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6918\u001b[0m       \u001b[32m0.6755\u001b[0m        \u001b[35m0.6915\u001b[0m  2.2860\n",
      "      2        \u001b[36m0.6915\u001b[0m       \u001b[32m0.6876\u001b[0m        \u001b[35m0.6912\u001b[0m  2.4742\n",
      "      3        \u001b[36m0.6912\u001b[0m       \u001b[32m0.6887\u001b[0m        \u001b[35m0.6908\u001b[0m  2.5580\n",
      "      4        \u001b[36m0.6909\u001b[0m       \u001b[32m0.6916\u001b[0m        \u001b[35m0.6903\u001b[0m  2.5080\n",
      "      5        \u001b[36m0.6904\u001b[0m       \u001b[32m0.7036\u001b[0m        \u001b[35m0.6897\u001b[0m  2.4290\n",
      "      6        \u001b[36m0.6897\u001b[0m       \u001b[32m0.7211\u001b[0m        \u001b[35m0.6889\u001b[0m  2.5474\n",
      "      7        \u001b[36m0.6890\u001b[0m       \u001b[32m0.7331\u001b[0m        \u001b[35m0.6880\u001b[0m  2.3531\n",
      "      8        \u001b[36m0.6881\u001b[0m       \u001b[32m0.7408\u001b[0m        \u001b[35m0.6870\u001b[0m  2.3830\n",
      "      9        \u001b[36m0.6871\u001b[0m       \u001b[32m0.7478\u001b[0m        \u001b[35m0.6858\u001b[0m  2.5000\n",
      "     10        \u001b[36m0.6859\u001b[0m       \u001b[32m0.7499\u001b[0m        \u001b[35m0.6845\u001b[0m  2.5347\n",
      "     11        \u001b[36m0.6846\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6829\u001b[0m  2.5021\n",
      "     12        \u001b[36m0.6831\u001b[0m       0.7494        \u001b[35m0.6812\u001b[0m  2.4803\n",
      "     13        \u001b[36m0.6813\u001b[0m       0.7491        \u001b[35m0.6791\u001b[0m  2.6323\n",
      "     14        \u001b[36m0.6793\u001b[0m       0.7475        \u001b[35m0.6767\u001b[0m  2.4790\n",
      "     15        \u001b[36m0.6770\u001b[0m       0.7486        \u001b[35m0.6740\u001b[0m  2.4100\n",
      "     16        \u001b[36m0.6743\u001b[0m       \u001b[32m0.7504\u001b[0m        \u001b[35m0.6708\u001b[0m  2.4360\n",
      "     17        \u001b[36m0.6711\u001b[0m       \u001b[32m0.7510\u001b[0m        \u001b[35m0.6670\u001b[0m  2.4805\n",
      "     18        \u001b[36m0.6674\u001b[0m       0.7506        \u001b[35m0.6626\u001b[0m  2.4719\n",
      "     19        \u001b[36m0.6630\u001b[0m       0.7500        \u001b[35m0.6574\u001b[0m  2.4987\n",
      "     20        \u001b[36m0.6579\u001b[0m       0.7496        \u001b[35m0.6514\u001b[0m  2.4657\n",
      "     21        \u001b[36m0.6520\u001b[0m       0.7488        \u001b[35m0.6442\u001b[0m  2.4876\n",
      "     22        \u001b[36m0.6449\u001b[0m       0.7484        \u001b[35m0.6359\u001b[0m  2.6065\n",
      "     23        \u001b[36m0.6368\u001b[0m       0.7485        \u001b[35m0.6263\u001b[0m  2.4512\n",
      "     24        \u001b[36m0.6273\u001b[0m       0.7482        \u001b[35m0.6152\u001b[0m  2.4120\n",
      "     25        \u001b[36m0.6164\u001b[0m       0.7484        \u001b[35m0.6026\u001b[0m  2.5304\n",
      "     26        \u001b[36m0.6040\u001b[0m       0.7491        \u001b[35m0.5886\u001b[0m  2.4812\n",
      "     27        \u001b[36m0.5903\u001b[0m       0.7498        \u001b[35m0.5734\u001b[0m  2.6820\n",
      "     28        \u001b[36m0.5754\u001b[0m       0.7504        \u001b[35m0.5575\u001b[0m  2.4210\n",
      "     29        \u001b[36m0.5598\u001b[0m       \u001b[32m0.7514\u001b[0m        \u001b[35m0.5414\u001b[0m  2.4760\n",
      "     30        \u001b[36m0.5441\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.5259\u001b[0m  2.4990\n",
      "     31        \u001b[36m0.5291\u001b[0m       \u001b[32m0.7562\u001b[0m        \u001b[35m0.5118\u001b[0m  2.4839\n",
      "     32        \u001b[36m0.5155\u001b[0m       \u001b[32m0.7586\u001b[0m        \u001b[35m0.4997\u001b[0m  2.4982\n",
      "     33        \u001b[36m0.5037\u001b[0m       \u001b[32m0.7615\u001b[0m        \u001b[35m0.4895\u001b[0m  2.4611\n",
      "     34        \u001b[36m0.4940\u001b[0m       \u001b[32m0.7651\u001b[0m        \u001b[35m0.4811\u001b[0m  2.5026\n",
      "     35        \u001b[36m0.4860\u001b[0m       \u001b[32m0.7701\u001b[0m        \u001b[35m0.4737\u001b[0m  2.5060\n",
      "     36        \u001b[36m0.4789\u001b[0m       \u001b[32m0.7763\u001b[0m        \u001b[35m0.4663\u001b[0m  2.4887\n",
      "     37        \u001b[36m0.4717\u001b[0m       \u001b[32m0.7836\u001b[0m        \u001b[35m0.4586\u001b[0m  2.4892\n",
      "     38        \u001b[36m0.4640\u001b[0m       \u001b[32m0.7944\u001b[0m        \u001b[35m0.4501\u001b[0m  2.4944\n",
      "     39        \u001b[36m0.4556\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.4414\u001b[0m  2.4935\n",
      "     40        \u001b[36m0.4466\u001b[0m       \u001b[32m0.8154\u001b[0m        \u001b[35m0.4329\u001b[0m  2.4904\n",
      "     41        \u001b[36m0.4384\u001b[0m       0.8045        0.4349  2.5541\n",
      "     42        0.4391       0.7854        0.4855  2.5701\n",
      "     43        0.4917       0.6424        0.6150  2.5600\n",
      "     44        0.6171       0.6682        0.9110  2.5521\n",
      "     45        0.9206       \u001b[32m0.8184\u001b[0m        0.4532  2.5481\n",
      "     46        0.4557       0.5286        0.6495  2.5431\n",
      "Stopping since valid_loss has not improved in the last 7 epochs.\n",
      "[CV 1/2; 3/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=75, bias=True), Sigmoid(), Linear(in_features=75, out_features=50, bias=True), ReLU(), Linear(in_features=50, out_features=1, bias=True)]; total time= 2.0min\n",
      "[CV 2/2; 3/3] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=75, bias=True), Sigmoid(), Linear(in_features=75, out_features=50, bias=True), ReLU(), Linear(in_features=50, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6918\u001b[0m       \u001b[32m0.6717\u001b[0m        \u001b[35m0.6915\u001b[0m  2.3254\n",
      "      2        \u001b[36m0.6915\u001b[0m       \u001b[32m0.6830\u001b[0m        \u001b[35m0.6913\u001b[0m  2.4811\n",
      "      3        \u001b[36m0.6912\u001b[0m       0.6817        \u001b[35m0.6909\u001b[0m  2.5222\n",
      "      4        \u001b[36m0.6909\u001b[0m       \u001b[32m0.6833\u001b[0m        \u001b[35m0.6904\u001b[0m  2.4900\n",
      "      5        \u001b[36m0.6904\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.6898\u001b[0m  2.4330\n",
      "      6        \u001b[36m0.6897\u001b[0m       \u001b[32m0.7132\u001b[0m        \u001b[35m0.6890\u001b[0m  2.4600\n",
      "      7        \u001b[36m0.6890\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6881\u001b[0m  2.4582\n",
      "      8        \u001b[36m0.6881\u001b[0m       \u001b[32m0.7320\u001b[0m        \u001b[35m0.6871\u001b[0m  2.4766\n",
      "      9        \u001b[36m0.6870\u001b[0m       \u001b[32m0.7372\u001b[0m        \u001b[35m0.6860\u001b[0m  2.5622\n",
      "     10        \u001b[36m0.6859\u001b[0m       \u001b[32m0.7398\u001b[0m        \u001b[35m0.6846\u001b[0m  2.5174\n",
      "     11        \u001b[36m0.6845\u001b[0m       0.7386        \u001b[35m0.6831\u001b[0m  2.5441\n",
      "     12        \u001b[36m0.6830\u001b[0m       0.7381        \u001b[35m0.6814\u001b[0m  2.5745\n",
      "     13        \u001b[36m0.6812\u001b[0m       0.7372        \u001b[35m0.6793\u001b[0m  2.5881\n",
      "     14        \u001b[36m0.6791\u001b[0m       0.7363        \u001b[35m0.6770\u001b[0m  2.5386\n",
      "     15        \u001b[36m0.6767\u001b[0m       0.7385        \u001b[35m0.6743\u001b[0m  2.5583\n",
      "     16        \u001b[36m0.6740\u001b[0m       \u001b[32m0.7404\u001b[0m        \u001b[35m0.6711\u001b[0m  2.5504\n",
      "     17        \u001b[36m0.6707\u001b[0m       \u001b[32m0.7415\u001b[0m        \u001b[35m0.6674\u001b[0m  2.5619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18        \u001b[36m0.6669\u001b[0m       \u001b[32m0.7417\u001b[0m        \u001b[35m0.6630\u001b[0m  2.4911\n",
      "     19        \u001b[36m0.6625\u001b[0m       0.7412        \u001b[35m0.6579\u001b[0m  2.4812\n",
      "     20        \u001b[36m0.6573\u001b[0m       0.7402        \u001b[35m0.6518\u001b[0m  2.4756\n",
      "     21        \u001b[36m0.6511\u001b[0m       0.7401        \u001b[35m0.6448\u001b[0m  2.4945\n",
      "     22        \u001b[36m0.6439\u001b[0m       0.7399        \u001b[35m0.6365\u001b[0m  2.4950\n",
      "     23        \u001b[36m0.6356\u001b[0m       0.7406        \u001b[35m0.6270\u001b[0m  2.5068\n",
      "     24        \u001b[36m0.6258\u001b[0m       0.7404        \u001b[35m0.6160\u001b[0m  2.5154\n",
      "     25        \u001b[36m0.6147\u001b[0m       0.7409        \u001b[35m0.6036\u001b[0m  2.5219\n",
      "     26        \u001b[36m0.6020\u001b[0m       0.7404        \u001b[35m0.5899\u001b[0m  2.5024\n",
      "     27        \u001b[36m0.5880\u001b[0m       0.7415        \u001b[35m0.5750\u001b[0m  2.4793\n",
      "     28        \u001b[36m0.5729\u001b[0m       \u001b[32m0.7421\u001b[0m        \u001b[35m0.5596\u001b[0m  2.5111\n",
      "     29        \u001b[36m0.5571\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.5441\u001b[0m  2.5109\n",
      "     30        \u001b[36m0.5414\u001b[0m       \u001b[32m0.7451\u001b[0m        \u001b[35m0.5295\u001b[0m  2.4957\n",
      "     31        \u001b[36m0.5264\u001b[0m       \u001b[32m0.7469\u001b[0m        \u001b[35m0.5163\u001b[0m  2.4953\n",
      "     32        \u001b[36m0.5130\u001b[0m       \u001b[32m0.7503\u001b[0m        \u001b[35m0.5051\u001b[0m  2.5040\n",
      "     33        \u001b[36m0.5016\u001b[0m       \u001b[32m0.7537\u001b[0m        \u001b[35m0.4959\u001b[0m  2.4940\n",
      "     34        \u001b[36m0.4922\u001b[0m       \u001b[32m0.7569\u001b[0m        \u001b[35m0.4881\u001b[0m  2.4825\n",
      "     35        \u001b[36m0.4845\u001b[0m       \u001b[32m0.7622\u001b[0m        \u001b[35m0.4810\u001b[0m  2.5197\n",
      "     36        \u001b[36m0.4775\u001b[0m       \u001b[32m0.7688\u001b[0m        \u001b[35m0.4737\u001b[0m  2.4536\n",
      "     37        \u001b[36m0.4704\u001b[0m       \u001b[32m0.7770\u001b[0m        \u001b[35m0.4654\u001b[0m  2.4900\n",
      "     38        \u001b[36m0.4627\u001b[0m       \u001b[32m0.7884\u001b[0m        \u001b[35m0.4565\u001b[0m  2.4706\n",
      "     39        \u001b[36m0.4541\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m0.4463\u001b[0m  2.5062\n",
      "     40        \u001b[36m0.4448\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m0.4378\u001b[0m  2.4793\n",
      "     41        \u001b[36m0.4364\u001b[0m       0.8050        \u001b[35m0.4371\u001b[0m  2.4946\n",
      "     42        0.4376       0.7806        0.4966  2.4939\n",
      "     43        0.4934       0.6390        0.6261  2.4847\n",
      "     44        0.6290       0.6402        0.9850  2.5041\n",
      "     45        0.9750       0.8108        0.4595  2.5034\n",
      "     46        0.4595       0.5323        0.6519  2.5081\n",
      "     47        0.6527       0.6957        0.5587  2.4925\n",
      "Stopping since valid_loss has not improved in the last 7 epochs.\n",
      "[CV 2/2; 3/3] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=75, bias=True), Sigmoid(), Linear(in_features=75, out_features=50, bias=True), ReLU(), Linear(in_features=50, out_features=1, bias=True)]; total time= 2.1min\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6918\u001b[0m       \u001b[32m0.6709\u001b[0m        \u001b[35m0.6915\u001b[0m  4.6319\n",
      "      2        \u001b[36m0.6915\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.6913\u001b[0m  4.8010\n",
      "      3        \u001b[36m0.6912\u001b[0m       0.6820        \u001b[35m0.6909\u001b[0m  4.7972\n",
      "      4        \u001b[36m0.6908\u001b[0m       \u001b[32m0.6825\u001b[0m        \u001b[35m0.6904\u001b[0m  5.0174\n",
      "      5        \u001b[36m0.6903\u001b[0m       \u001b[32m0.6956\u001b[0m        \u001b[35m0.6898\u001b[0m  4.9266\n",
      "      6        \u001b[36m0.6897\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6890\u001b[0m  4.7030\n",
      "      7        \u001b[36m0.6890\u001b[0m       \u001b[32m0.7262\u001b[0m        \u001b[35m0.6881\u001b[0m  4.8081\n",
      "      8        \u001b[36m0.6881\u001b[0m       \u001b[32m0.7346\u001b[0m        \u001b[35m0.6871\u001b[0m  4.8096\n",
      "      9        \u001b[36m0.6871\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.6860\u001b[0m  4.7120\n",
      "     10        \u001b[36m0.6859\u001b[0m       \u001b[32m0.7423\u001b[0m        \u001b[35m0.6846\u001b[0m  4.8021\n",
      "     11        \u001b[36m0.6845\u001b[0m       0.7414        \u001b[35m0.6831\u001b[0m  4.7300\n",
      "     12        \u001b[36m0.6830\u001b[0m       0.7406        \u001b[35m0.6813\u001b[0m  4.7047\n",
      "     13        \u001b[36m0.6812\u001b[0m       0.7394        \u001b[35m0.6793\u001b[0m  4.7640\n",
      "     14        \u001b[36m0.6792\u001b[0m       0.7387        \u001b[35m0.6769\u001b[0m  4.8334\n",
      "     15        \u001b[36m0.6768\u001b[0m       0.7399        \u001b[35m0.6742\u001b[0m  4.6620\n",
      "     16        \u001b[36m0.6741\u001b[0m       0.7422        \u001b[35m0.6710\u001b[0m  4.7840\n",
      "     17        \u001b[36m0.6708\u001b[0m       \u001b[32m0.7433\u001b[0m        \u001b[35m0.6673\u001b[0m  4.7771\n",
      "     18        \u001b[36m0.6671\u001b[0m       \u001b[32m0.7440\u001b[0m        \u001b[35m0.6629\u001b[0m  4.7541\n",
      "     19        \u001b[36m0.6627\u001b[0m       0.7435        \u001b[35m0.6577\u001b[0m  4.8360\n",
      "     20        \u001b[36m0.6575\u001b[0m       0.7427        \u001b[35m0.6517\u001b[0m  4.7971\n",
      "     21        \u001b[36m0.6514\u001b[0m       0.7424        \u001b[35m0.6446\u001b[0m  4.8970\n",
      "     22        \u001b[36m0.6443\u001b[0m       0.7424        \u001b[35m0.6363\u001b[0m  4.6990\n",
      "     23        \u001b[36m0.6360\u001b[0m       0.7429        \u001b[35m0.6268\u001b[0m  4.7030\n",
      "     24        \u001b[36m0.6263\u001b[0m       0.7431        \u001b[35m0.6158\u001b[0m  4.5866\n",
      "     25        \u001b[36m0.6153\u001b[0m       0.7431        \u001b[35m0.6033\u001b[0m  4.6830\n",
      "     26        \u001b[36m0.6027\u001b[0m       0.7428        \u001b[35m0.5895\u001b[0m  4.6701\n",
      "     27        \u001b[36m0.5888\u001b[0m       0.7435        \u001b[35m0.5746\u001b[0m  4.7580\n",
      "     28        \u001b[36m0.5737\u001b[0m       \u001b[32m0.7443\u001b[0m        \u001b[35m0.5590\u001b[0m  4.8733\n",
      "     29        \u001b[36m0.5580\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m0.5434\u001b[0m  4.6940\n",
      "     30        \u001b[36m0.5422\u001b[0m       \u001b[32m0.7471\u001b[0m        \u001b[35m0.5286\u001b[0m  4.7155\n",
      "     31        \u001b[36m0.5271\u001b[0m       \u001b[32m0.7493\u001b[0m        \u001b[35m0.5153\u001b[0m  4.8125\n",
      "     32        \u001b[36m0.5136\u001b[0m       \u001b[32m0.7519\u001b[0m        \u001b[35m0.5039\u001b[0m  4.7351\n",
      "     33        \u001b[36m0.5020\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.4946\u001b[0m  4.8209\n",
      "     34        \u001b[36m0.4924\u001b[0m       \u001b[32m0.7578\u001b[0m        \u001b[35m0.4868\u001b[0m  4.7463\n",
      "     35        \u001b[36m0.4846\u001b[0m       \u001b[32m0.7635\u001b[0m        \u001b[35m0.4799\u001b[0m  4.6166\n",
      "     36        \u001b[36m0.4775\u001b[0m       \u001b[32m0.7701\u001b[0m        \u001b[35m0.4728\u001b[0m  4.8010\n",
      "     37        \u001b[36m0.4704\u001b[0m       \u001b[32m0.7778\u001b[0m        \u001b[35m0.4650\u001b[0m  4.7329\n",
      "     38        \u001b[36m0.4626\u001b[0m       \u001b[32m0.7888\u001b[0m        \u001b[35m0.4564\u001b[0m  4.8230\n",
      "     39        \u001b[36m0.4541\u001b[0m       \u001b[32m0.7952\u001b[0m        \u001b[35m0.4471\u001b[0m  4.6461\n",
      "     40        \u001b[36m0.4450\u001b[0m       \u001b[32m0.8115\u001b[0m        \u001b[35m0.4387\u001b[0m  4.8291\n",
      "     41        \u001b[36m0.4367\u001b[0m       0.8033        \u001b[35m0.4386\u001b[0m  4.7531\n",
      "     42        0.4370       0.7850        0.4879  4.8423\n",
      "     43        0.4863       0.6647        0.5926  4.6630\n",
      "     44        0.5917       0.6739        0.8306  4.7712\n",
      "     45        0.8284       0.7513        0.4912  4.6711\n",
      "     46        0.4906       0.7193        0.5109  4.7246\n",
      "     47        0.5105       0.7032        0.6101  4.7260\n",
      "Stopping since valid_loss has not improved in the last 7 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV and output the best performing parameters\n",
    "\n",
    "#parameters to test using gridsearch\n",
    "params = {\n",
    "    'lr': [0.2], \n",
    "    'max_epochs': [100],\n",
    "    #pass parameters to NetModule constructor to set architecture\n",
    "    'module__net_modules': included_modules\n",
    "} \n",
    "\n",
    "# Perform grid search with 2-fold cross validation, will refit model at the end using best params on entire training set\n",
    "gs = GridSearchCV(net, params, refit=True, cv=2, scoring=precision_scorer, verbose=10)\n",
    "\n",
    "start_time = time.time()\n",
    "gs.fit(dataset.train, dataset.labels_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "model_output = (elapsed_time, gs) \n",
    "pickle.dump( model_output, open( \"default_model.p\", \"wb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "willing-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Precision: 0.9756385400492267\n",
      "Best Parameters: {'lr': 0.2, 'max_epochs': 100, 'module__net_modules': [Linear(in_features=22, out_features=75, bias=True), Sigmoid(), Linear(in_features=75, out_features=50, bias=True), ReLU(), Linear(in_features=50, out_features=1, bias=True)]}\n"
     ]
    }
   ],
   "source": [
    "elapsed, gs = pickle.load( open( \"default_model.p\", \"rb\" ) )\n",
    "print(\"Best Precision: \" + str(gs.best_score_) + \"\\nBest Parameters: \" + str(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "searching-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 1039.0 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Time: \" + '{0:.5}'.format(elapsed) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "guided-register",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Test Data: 0.9370329057445622\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.predict(dataset.test)\n",
    "  \n",
    "print(\"Precision on Test Data: \" + str(precision_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "formed-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on Test Data: 0.6562506103158018\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall on Test Data: \" + str(recall_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "minus-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806679905768744\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "working-recorder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28188cec040>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(dataset.labels_test, y_pred), display_labels=[\"Not Defaulted\", \"Defaulted\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "historic-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = roc_curve(dataset.labels_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "curious-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x282bfe72d30>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkkklEQVR4nO3de3RcZ3nv8e9jWfJFluSR5bsljR2ci+MkvoxyIUACgRAgTeAk5FLSEprTUCCUFso6aWGlrPRKU+ghbU6LgazQHiBcWlhuCaQtJU0PEGI5dhI7IalxLF8l2ZYsyZZ1f84fe894rOgyjrVnNLN/n7W0PHvPnplnW/Z+Zr/v876vuTsiIhJfMwodgIiIFJYSgYhIzCkRiIjEnBKBiEjMKRGIiMTczEIHcKbq6uo8mUwWOgwRkaKydevWI+6+cKznii4RJJNJmpubCx2GiEhRMbOW8Z5T05CISMwpEYiIxJwSgYhIzCkRiIjEnBKBiEjMRZYIzOxhM2s3sx3jPG9m9qCZ7TKz58xsQ1SxiIjI+KK8I3gEuG6C598BrA5/7gb+NsJYRERkHJElAnd/EuiY4JAbgb/3wFPAfDNbGlU8IiLFqHdgiJ/uOsIX/v2/2XmwK5LPKOSAsuXAvqzt/eG+Q6MPNLO7Ce4aaGhoyEtwIiKF0N7Tx9Y9nWzZ00lzSwc7D3YzPOKYQe28Ci5cVjPln1kUI4vdfROwCSCVSmklHREpCe7OLw+foHlPR+bC33K0F4BZM2ewrn4+H7rqHFLJBOsbEtTMKY8kjkImggNAfdb2inCfiEhJ6h8aZseB7syFf2tLB529gwDUVlaQakxwx2WNbEwmWLushoqZ+SnsLGQi2AzcY2aPApcBXe7+qmYhEZFi1dU7yDN7O9myp4PmPZ08u/8Y/UMjAKysq+StFyymKVnLxmSCVXWVmFlB4owsEZjZN4CrgToz2w/8IVAO4O5/BzwGvBPYBfQCH4gqFhGRqLk7B46dpHnPqQv/y+09uMPMGcaFy2v4tcsbSSUTbGysZWHVrEKHnBFZInD32yd53oGPRPX5IiJRGh5xftHanbnwb23p5FBXHwDzZs1kQ2OC6y9eysZkgnX185lbMX27ZKdvZCIi00jvwBDb9x3LXPi37T3G8f4hAJZUz6ZpZS1NyQQbGxOcv6SashmFaeZ5LZQIRETGcLinn60t6WqeTnYe6GIoLOM8b3EV716/LGjfb0ywfP6cgrXvTwUlAhGJPXdn95ETWdU8nbxy5AQAFWEZ5wevWkWqsZYNDQlq5kZTxlkoSgQiEjsDQyPsONh12oW/48QAAIm55aSStdzWVE8qWcva5dXMmllW4IijpUQgIiWv62RQxtkcVvNs33eqjDO5YC5vOX8RqcYEqWQt5ywsXBlnoSgRiEjJCco4OzJlnC+1BWWcZTOMtcuquePyRlKNCTYmEyyqml3ocAtOiUBEitrwiPNSaw/NLcFFv3lPBwfDMs7KijI2NCZ4x9qlNCUTrGuY3mWchaK/EREpKicHhsMyzg6aWzp5pqWTnrCMc3H1LJqStdwdNvOcv6SKmWVaf2sySgQiMq0dOd6f+abf3NLJjrCME4IyzhvWLSOVTJBqrGVForjLOAtFiUBEpg1355UjJ4ILf9jUszu7jHPFfH7zTatoSibY0JBg/tyKAkdcGpQIRKRgBoZG2Hmw67QL/9GwjHP+3HJSjbXc0lRPUzLB2uU1JV/GWShKBCKSN919gzzTEtTtb9nTwfZ9x+gbDMo4GxfM5erzFpFKJmhKJlhVN48ZRTRNQzFTIhCRyBw8djIzIduWPZ38orU7U8Z54bJqfvXSxrB9P8GiapVxFooSgYhMieER5+W2HppbTg3cOnDsJHCqjPNj16ymKVnLuvr5VM7S5We60G9CRF6TvsGgjDPdzLO1pZOevqCMc1HVLJpW1vI/37iSJpVxTntKBCKSk6PH+2nOat/fcaCLweGgjPPcxfP4lUuWkWpM0JRUGWexUSIQkVdxd/Yc7Q2+6e/pZEtLB7sPh2WcZTO4pL6Gu96wKjP/vso4i5sSgYgwODzCzoPdmbb95pYOjhzPLuNM8N6Np8o4Z5erjLOUKBGIxFBP3yDb9h7LTMO8fd8xTg4OA9BQO5c3nbuQVGOw4tY5C1XGWeqUCERi4FDXycw0DekyzhGHGQYXLqvh1qZ6mpK1pJIJFquMM3aUCERKzMiI83J7z2kX/nQZ59yKMjY0JPjoW8Iyzob5zFMZZ+zpX4BIkesbHObZfccy9ftbWzrpDss4F1bNoimZ4K43BGWcFyxVGae8mhKBSJHpODHA1pbOzMIrz2eVca5eNI93Xbw0bN+vpb5WZZwyOSUCkWnM3dnb0cuWPacu/L/MKuO8aEUNv/GGlTQ11rKxMUGiUmWccuaUCESmkcHhEV481J114e/kyPF+AGrmlLOxMcFNG1fQlKzlIpVxyhRRIhApoOP9Q2zb25m58G/be6qMs752Dm9cXRfOxlnL61TGKRFRIhDJo9auvsy8+1v2dPDioVNlnGuWVXNrU31mta0lNSrjlPxQIhCJyMiIs+vwcbbsOXXh398ZlHHOKS9jfcN87nnLapqSCdY3JFTGKQWjf3kiU6RvcJjnD3RlLvxbWzrpOjkIQN28oIzzA1eupCmZ4IKl1ZSrjFOmCSUCkdeoMyzj3BI29Ty/v4uB4WC1rdctmsc71i4hlQymaWionasyTpm2lAhEcuDu7OsIVttqbgmqeXa1HwegvMy4aHkNH7gySSoZlHHWqoxTikikicDMrgO+AJQBX3b3Px/1fAPwVWB+eMy97v5YlDGJ5GJoeIQXD/VkLvzNezpp7wnKOKtnz2RjY4L3rF9OU7KWi1eojFOKW2SJwMzKgIeAtwH7gS1mttndX8g67NPAt9z9b81sDfAYkIwqJpHxnOgfYtveY5kL/7a9x+gdCMo4VyTm8PpzFoTNPLWsXqQyTiktUd4RXArscvfdAGb2KHAjkJ0IHKgOH9cAByOMRySjrbsvU8nT3NLBi4d6GB5xZhicv6Sa925cQSqcjXNpzZxChysSqSgTwXJgX9b2fuCyUcd8BvhXM/soUAm8daw3MrO7gbsBGhoapjxQKW0jI84vDx8/NVq3pYN9HafKONfVz+cjV59DKlnL+ob5VM0uL3DEIvlV6M7i24FH3P1zZnYF8A9mttbdR7IPcvdNwCaAVCrlBYhTikj/0DDP7+/KXPi37u3kWG+6jLOCVGMt778iSVOyljXLVMYpEmUiOADUZ22vCPdluwu4DsDdf2Zms4E6oD3CuKTEHOsNyzj3dLK1pYNn93cxMBR8lzhnYSVvX7MkM01D4wKVcYqMFmUi2AKsNrOVBAngNuBXRx2zF7gGeMTMLgBmA4cjjEmKnLuzvzMo40xf+F9uO1XGuXZ5DXe+PkmqMVhUfcG8WQWOWGT6iywRuPuQmd0DPE5QGvqwu+80s/uBZnffDHwC+JKZ/S5Bx/Gd7q6mH8kYGh7hF609mdG6zS0dtHUHZZxVYRnnjeuWk2pMcEn9fJVxirwGkfYRhGMCHhu1776sxy8AV0YZgxSXE/1DbN93LHPh37a3kxNhGefy+XO4fNWCzGjdcxdVqYxTZAoUurNYYq69u4/mlqCMc2tLJzsPdjM84lhYxnlTuoyzMcGy+SrjFImCEoHkjfupMs70hb/laC8As8tnsK5+Ph/OKuOsVhmnSF4oEUhk+oeG2XEgXcYZdOx2hmWcCyorSCUT/NrljaSStVyoMk6RglEikCnT1TvI1r1hNc+eTrbvP5Yp41xVV8nb1izOTNOQVBmnyLShRCCvSbqMMz0hW/OeTl5q6wFg5oygjPP9VzRmZuOsUxmnyLSlRCA5GR5xXjzUTfOeDppbggt/a3cfAFWzZrKhMcGvXLKUVLKWS1bMZ06FyjhFioUSgYypd2CI7XuPBe374Wycx/uHAFhWM5tLVwYlnKlkLecurqJMZZwiRUuJQABo7+lj657O8Nt+BzuyyjjPW1zFe9YvDxZVT9ayXGWcIiVFiSCGgjLOE1nNPB3sCcs4Z80Myjg/dNU5pMJF1WvmqIxTpJQpEcTAwNAIzx/oYmtLen6eTjpODABQW1lBqjHB+y5rJJVMcOGyGipmqoxTJE5yTgRmNtfde6MMRqZG18lBnmnpzKyt++y+Y/SHZZwr6yq55vxFNIWLrqysq1QZp0jMTZoIzOz1wJeBeUCDmV0CfNDdPxx1cDI5d+fAsZOZCdnSZZzuQRnnhctrMoO2NjYmWFilMk4ROV0udwR/Bbwd2Azg7s+a2ZsijUrGNTzi/KK1O7zwB+37h7qCMs55YRnnuy4KyjjX1auMU0Qml1PTkLvvG9V8MBxNODLayYFhtu0LRupuaenkmZbOTBnn0prZmZk4U421nLdEZZwicuZySQT7wuYhN7Ny4GPAi9GGFV9HjveHI3U72NLSyc4DXQxllXG+e/2ysH1fZZwiMjVySQS/BXyBYDH6A8C/AuofmALuzu4jJ4Jv+2Ep5ytHTgBBGecl9fP54FWrSCVr2aAyThGJSC6J4Dx3f1/2DjO7EvhJNCGVroGhEXYe7KI5axrmo2EZZ2JuOalkLbdfWk8qWctalXGKSJ7kkgj+GtiQwz4ZpevkIM/s7cx849+eVcaZXDCXN5+/iKZkgo2NtZyzUGWcIlIY4yYCM7sCeD2w0Mw+nvVUNcEaxDJKUMbZkfnGny7jLJthrF1WzR2XN2Yu/CrjFJHpYqI7ggqCsQMzgaqs/d3AzVEGVQyGR5yX23qCTt2wc/dgVhnn+ob5vPOipaSSCdbVz2duhQZxi8j0NO7Vyd3/E/hPM3vE3VvyGNO0dHJgmGf3H8tc+J9p6aQnLONcXD2LpmQtHwxH656/pFplnCJSNHL5mtprZg8AFwKz0zvd/S2RRTVNjIw4//tH/82TLx9mR1jGCUEZ5w3rgjLOjY0JViTmqH1fRIpWLonga8A3gesJSknfDxyOMqjp4pWjJ3jwR//NBUuruftNq0glE2xsqKVmrso4RaR05JIIFrj7V8zsY1nNRVuiDmw6aAvb/O+7fg1XnLOgwNGIiEQjl0QwGP55yMzeBRwEaqMLafpo6wkSweJqVfiISOnKJRH8sZnVAJ8gGD9QDfxOlEFNF61d/QAsrp49yZEiIsVr0kTg7v8SPuwC3gyZkcUlr627j6pZM6mcpdJPESldEw0oKwNuIZhj6IfuvsPMrgf+AJgDrM9PiIXT3tPHIjULiUiJm+ir7leAeuBp4EEzOwikgHvd/Xt5iK3gWrv61CwkIiVvokSQAi529xEzmw20Aue4+9H8hFZ4bd39XLYyFv3iIhJjE01vOeDuIwDu3gfsPtMkYGbXmdlLZrbLzO4d55hbzOwFM9tpZl8/k/ePkruHTUO6IxCR0jbRHcH5ZvZc+NiAc8JtA9zdL57ojcM+hoeAtwH7gS1mttndX8g6ZjXw+8CV7t5pZovO4lymVMeJAQaHXaWjIlLyJkoEF5zle18K7HL33QBm9ihwI/BC1jG/CTzk7p0A7t5+lp85Zdq6g9LRJbojEJESN9Gkc2c70dxyYF/W9n7gslHHnAtgZj8hmNr6M+7+w9FvZGZ3A3cDNDQ0nGVYuUkPJlPTkIiUukIvgTUTWA1cDdwOfMnM5o8+yN03uXvK3VMLFy7MS2Dp6SXUNCQipS7KRHCAoPw0bUW4L9t+YLO7D7r7K8DLBImh4NJNQ4uqdEcgIqUtp0RgZnPM7LwzfO8twGozW2lmFcBtwOZRx3yP4G4AM6sjaCrafYafE4m2nj4WVFZo3WARKXmTXuXM7FeA7cAPw+11Zjb6gv4q7j4E3AM8DrwIfMvdd5rZ/WZ2Q3jY48BRM3sB+DHwyekyTqGtS6WjIhIPuUyi8xmCCqAnANx9u5mtzOXN3f0x4LFR++7LeuzAx8OfaaWtp48l6h8QkRjIpd1j0N27Ru3zKIKZTtq6+zW9hIjEQi53BDvN7FeBsnAA2G8DP402rMIaHB7hyPF+NQ2JSCzkckfwUYL1ivuBrxNMR/07EcZUcEeO9+OuwWQiEg+53BGc7+6fAj4VdTDTRbp0VGMIRCQOcrkj+JyZvWhmf2RmayOPaBpozQwm0x2BiJS+SROBu7+ZYGWyw8AXzex5M/t05JEVUHuPEoGIxEdOo6XcvdXdHwR+i2BMwX0Tv6K4tXX3UTbDWFBZUehQREQil8uAsgvM7DNm9jzB4vU/JZguomS1dvWzqGoWM2ZYoUMREYlcLp3FDwPfBN7u7gcjjmdaaO/REpUiEh+TJgJ3vyIfgUwnbd19rKyrLHQYIiJ5MW4iMLNvufstYZNQ9kjinFYoK2atXX1cvmpBocMQEcmLie4IPhb+eX0+ApkuTg4M0903pKYhEYmNcTuL3f1Q+PDD7t6S/QN8OD/h5Z9KR0UkbnIpH33bGPveMdWBTBetWplMRGJmoj6CDxF8819lZs9lPVUF/CTqwAqlrUeL1otIvEzUR/B14AfAnwH3Zu3vcfeOSKMqoPZuLVovIvEyUSJwd99jZh8Z/YSZ1ZZqMmjt6mN2+QyqZ+cyxEJEpPhNdkdwPbCVoHw0e5itA6sijKtg2nr6WVI9GzONKhaReBg3Ebj79eGfOS1LWSraurVWsYjESy5zDV1pZpXh4zvM7PNm1hB9aIXR1q3pJUQkXnIpH/1boNfMLgE+AfwS+IdIoyoQd6etW4vWi0i85JIIhtzdgRuBv3H3hwhKSEtOd98QfYMjuiMQkVjJpTSmx8x+H/g14I1mNgMojzaswmhT6aiIxFAudwS3Eixc/xvu3kqwFsEDkUZVIOlEoMFkIhInuSxV2Qp8Dagxs+uBPnf/+8gjKwAtWi8icZRL1dAtwNPAe4FbgJ+b2c1RB1YI6TsC9RGISJzk0kfwKaDJ3dsBzGwh8O/Ad6IMrBDauvuomVPO7PKyQociIpI3ufQRzEgngdDRHF9XdIIxBGoWEpF4yeWO4Idm9jjwjXD7VuCx6EIqnNbufjULiUjs5LJm8SfN7H8Abwh3bXL370YbVmG0d/exelFdocMQEcmridYjWA38JXAO8Dzwe+5+IF+B5dvIiNPe06+mIRGJnYna+h8G/gW4iWAG0r8+0zc3s+vM7CUz22Vm905w3E1m5maWOtPPmCpHTwwwPOJqGhKR2JmoaajK3b8UPn7JzJ45kzc2szLgIYKlLvcDW8xss7u/MOq4KuBjwM/P5P2nWmZUcZUSgYjEy0SJYLaZrefUOgRzsrfdfbLEcCmwy913A5jZowTzFb0w6rg/Aj4LfPIMY59SmVHFNUoEIhIvEyWCQ8Dns7Zbs7YdeMsk770c2Je1vR+4LPsAM9sA1Lv7981s3ERgZncDdwM0NEQzA7ZGFYtIXE20MM2bo/zgcPK6zwN3Tnasu28CNgGkUimPIp7W7j7MoG6eEoGIxEuUA8MOAPVZ2yvCfWlVwFrgCTPbA1wObC5Uh3F7dx9182ZRXlaSY+VERMYV5VVvC7DazFaaWQVwG7A5/aS7d7l7nbsn3T0JPAXc4O7NEcY0Lo0qFpG4iiwRuPsQcA/wOPAi8C1332lm95vZDVF97mvV2t3PYlUMiUgMTTqy2MwMeB+wyt3vD9crXuLuT0/2Wnd/jFHTUbj7feMce3VOEUekvbuP9Q3zCxmCiEhB5HJH8H+AK4Dbw+0egvEBJWNgaISjJwZ0RyAisZTLpHOXufsGM9sG4O6dYZt/yWjvSa9DoD4CEYmfXO4IBsNRwg6Z9QhGIo0qzzJjCDSYTERiKJdE8CDwXWCRmf0J8P+AP400qjxrT69MpqYhEYmhXKah/pqZbQWuIZhe4t3u/mLkkeVRa7eahkQkvnKpGmoAeoF/zt7n7nujDCyf2rr7KS8zaitLqutDRCQnuXQWf5+gf8CA2cBK4CXgwgjjyqv27j4WVc0mqJQVEYmXXJqGLsreDieK+3BkERVAq0YVi0iMnfHI4nD66csmPbCItHX3afppEYmtXPoIPp61OQPYAByMLKICaO/u542rFxY6DBGRgsilj6Aq6/EQQZ/BP0YTTv6d6B+ip39IS1SKSGxNmAjCgWRV7v57eYon706tTKY+AhGJp3H7CMxsprsPA1fmMZ68y4wq1mAyEYmpie4IniboD9huZpuBbwMn0k+6+z9FHFteZBatV9OQiMRULn0Es4GjBGsUp8cTOFBSiUBVQyISVxMlgkVhxdAOTiWAtEjWDS6Etu5+KivKmDcrl5woIlJ6Jrr6lQHzOD0BpJVQIuhTxZCIxNpEieCQu9+ft0gKRIlAROJuopHFsZh4p61H00uISLxNlAiuyVsUBeLutHX3645ARGJt3ETg7h35DKQQjvUOMjA0okQgIrF2xpPOlZK2zFrFSgQiEl+xTgStXVqZTEQk1omgPT29hO4IRCTGYp0ITk0voTsCEYmvWCeC1u4+EnPLmTWzrNChiIgUTKwTgUpHRURingjaezSqWEQk1omgtUujikVEYpsIhoZHOHK8nyW6IxCRmIs0EZjZdWb2kpntMrN7x3j+42b2gpk9Z2Y/MrPGKOPJdvTEACOuBWlERCJLBOF6xw8B7wDWALeb2ZpRh20DUu5+MfAd4C+iime0U4PJlAhEJN6ivCO4FNjl7rvdfQB4FLgx+wB3/7G794abTwErIoznNJmVyZQIRCTmokwEy4F9Wdv7w33juQv4wVhPmNndZtZsZs2HDx+ekuDaetKjitVZLCLxNi06i83sDiAFPDDW8+6+yd1T7p5auHDhlHxmW1cfZTOMBfOUCEQk3qJcqPcAUJ+1vSLcdxozeyvwKeAqd++PMJ7TtHX3sXDeLMpmxGL9HRGRcUV5R7AFWG1mK82sArgN2Jx9gJmtB74I3ODu7RHG8iptPf1qFhIRIcJE4O5DwD3A48CLwLfcfaeZ3W9mN4SHPQDMA75tZtvNbPM4bzfl2rr6VDoqIkK0TUO4+2PAY6P23Zf1+K1Rfv5E2nr6uHRlbaE+XkRk2pgWncX51jc4zLHeQTUNiYgQ00SQXpBGTUMiIjFNBOm1ijWYTEQkromgW9NLiIikxTIRaNF6EZFTYpkI2nv6mTVzBjVzygsdiohIwcUyEbR1ByuTmWlUsYhILBOBViYTETkllomgvUeL1ouIpMUuEbh7pmlIRERimAh6+ofoHRhW05CISCh2iaBdYwhERE4Tu0TQ1p1emUyJQEQEYpgItGi9iMjpYpcI0vMMqY9ARCQQu0TQ3t1P1eyZzK2IdCkGEZGiEbtEoNJREZHTxS4RtHZrVLGISLbYJYL2bo0qFhHJFqtEMDLitPeoaUhEJFusEkFH7wCDw87iKjUNiYikxSoRpFcmW1KjOwIRkbRYJQItWi8i8mqxSgStmmdIRORVYpUI0k1Di9RHICKSEbNE0E/dvArKy2J12iIiE4rVFbGtu49FVWoWEhHJFrtEoIohEZHTxSwR9Gt6CRGRUWKTCAaHRzh6ol9NQyIio8QmERzu6cddg8lEREaLNBGY2XVm9pKZ7TKze8d4fpaZfTN8/udmlowqlrZuLUgjIjKWyBKBmZUBDwHvANYAt5vZmlGH3QV0uvvrgL8CPhtVPKfGEOiOQEQkW5R3BJcCu9x9t7sPAI8CN4465kbgq+Hj7wDXmJlFEUx60Xo1DYmInC7KRLAc2Je1vT/cN+Yx7j4EdAELRr+Rmd1tZs1m1nz48OHXFMzSmtlcu2YxtXMrXtPrRURKVVEs3Ovum4BNAKlUyl/Le1x74RKuvXDJlMYlIlIKorwjOADUZ22vCPeNeYyZzQRqgKMRxiQiIqNEmQi2AKvNbKWZVQC3AZtHHbMZeH/4+GbgP9z9NX3jFxGR1yaypiF3HzKze4DHgTLgYXffaWb3A83uvhn4CvAPZrYL6CBIFiIikkeR9hG4+2PAY6P23Zf1uA94b5QxiIjIxGIzslhERMamRCAiEnNKBCIiMadEICISc1Zs1ZpmdhhoeY0vrwOOTGE4xUDnHA8653g4m3NudPeFYz1RdIngbJhZs7unCh1HPumc40HnHA9RnbOahkREYk6JQEQk5uKWCDYVOoAC0DnHg845HiI551j1EYiIyKvF7Y5ARERGUSIQEYm5kkwEZnadmb1kZrvM7N4xnp9lZt8Mn/+5mSULEOaUyuGcP25mL5jZc2b2IzNrLEScU2myc8467iYzczMr+lLDXM7ZzG4Jf9c7zezr+Y5xquXwb7vBzH5sZtvCf9/vLEScU8XMHjazdjPbMc7zZmYPhn8fz5nZhrP+UHcvqR+CKa9/CawCKoBngTWjjvkw8Hfh49uAbxY67jyc85uBueHjD8XhnMPjqoAngaeAVKHjzsPveTWwDUiE24sKHXceznkT8KHw8RpgT6HjPstzfhOwAdgxzvPvBH4AGHA58POz/cxSvCO4FNjl7rvdfQB4FLhx1DE3Al8NH38HuMbMLI8xTrVJz9ndf+zuveHmUwQrxhWzXH7PAH8EfBboy2dwEcnlnH8TeMjdOwHcvT3PMU61XM7ZgerwcQ1wMI/xTTl3f5JgfZbx3Aj8vQeeAuab2dKz+cxSTATLgX1Z2/vDfWMe4+5DQBewIC/RRSOXc852F8E3imI26TmHt8z17v79fAYWoVx+z+cC55rZT8zsKTO7Lm/RRSOXc/4McIeZ7SdY/+Sj+QmtYM70//ukimLxepk6ZnYHkAKuKnQsUTKzGcDngTsLHEq+zSRoHrqa4K7vSTO7yN2PFTKoiN0OPOLunzOzKwhWPVzr7iOFDqxYlOIdwQGgPmt7RbhvzGPMbCbB7eTRvEQXjVzOGTN7K/Ap4AZ3789TbFGZ7JyrgLXAE2a2h6AtdXORdxjn8nveD2x290F3fwV4mSAxFKtczvku4FsA7v4zYDbB5GylKqf/72eiFBPBFmC1ma00swqCzuDNo47ZDLw/fHwz8B8e9sIUqUnP2czWA18kSALF3m4Mk5yzu3e5e527J909SdAvcoO7Nxcm3CmRy7/t7xHcDWBmdQRNRbvzGONUy+Wc9wLXAJjZBQSJ4HBeo8yvzcCvh9VDlwNd7n7obN6w5JqG3H3IzO4BHieoOHjY3Xea2f1As7tvBr5CcPu4i6BT5rbCRXz2cjznB4B5wLfDfvG97n5DwYI+Szmec0nJ8ZwfB641sxeAYeCT7l60d7s5nvMngC+Z2e8SdBzfWcxf7MzsGwTJvC7s9/hDoBzA3f+OoB/kncAuoBf4wFl/ZhH/fYmIyBQoxaYhERE5A0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBDItmdmwmW3P+klOcOzxKfi8R8zslfCznglHqJ7pe3zZzNaEj/9g1HM/PdsYw/dJ/73sMLN/NrP5kxy/rthn45ToqXxUpiUzO+7u86b62Ane4xHgX9z9O2Z2LfCX7n7xWbzfWcc02fua2VeBl939TyY4/k6CWVfvmepYpHTojkCKgpnNC9dReMbMnjezV800amZLzezJrG/Mbwz3X2tmPwtf+20zm+wC/STwuvC1Hw/fa4eZ/U64r9LMvm9mz4b7bw33P2FmKTP7c2BOGMfXwueOh38+ambvyor5ETO72czKzOwBM9sSzjH/wRz+Wn5GONmYmV0anuM2M/upmZ0XjsS9H7g1jOXWMPaHzezp8NixZmyVuCn03Nv60c9YPwSjYreHP98lGAVfHT5XRzCqMn1Hezz88xPAp8LHZQTzDdURXNgrw/3/C7hvjM97BLg5fPxe4OfARuB5oJJgVPZOYD1wE/ClrNfWhH8+QbjmQTqmrGPSMb4H+Gr4uIJgFsk5wN3Ap8P9s4BmYOUYcR7POr9vA9eF29XAzPDxW4F/DB/fCfxN1uv/FLgjfDyfYC6iykL/vvVT2J+Sm2JCSsZJd1+X3jCzcuBPzexNwAjBN+HFQGvWa7YAD4fHfs/dt5vZVQSLlfwknFqjguCb9FgeMLNPE8xTcxfB/DXfdfcTYQz/BLwR+CHwOTP7LEFz0n+dwXn9APiCmc0CrgOedPeTYXPUxWZ2c3hcDcFkca+Mev0cM9senv+LwL9lHf9VM1tNMM1C+Tiffy1wg5n9Xrg9G2gI30tiSolAisX7gIXARncftGBG0dnZB7j7k2GieBfwiJl9HugE/s3db8/hMz7p7t9Jb5jZNWMd5O4vW7DWwTuBPzazH7n7/bmchLv3mdkTwNuBWwkWWoFgtamPuvvjk7zFSXdfZ2ZzCebf+QjwIMECPD929/eEHetPjPN6A25y95dyiVfiQX0EUixqgPYwCbwZeNWayxasw9zm7l8Cvkyw3N9TwJVmlm7zrzSzc3P8zP8C3m1mc82skqBZ57/MbBnQ6+7/l2Ayv7HWjB0M70zG8k2CicLSdxcQXNQ/lH6NmZ0bfuaYPFht7reBT9ipqdTTUxHfmXVoD0ETWdrjwEctvD2yYFZaiTklAikWXwNSZvY88OvAL8Y45mrgWTPbRvBt+wvufpjgwvgNM3uOoFno/Fw+0N2fIeg7eJqgz+DL7r4NuAh4Omyi+UPgj8d4+SbguXRn8Sj/SrAw0L97sPwiBInrBeAZCxYt/yKT3LGHsTxHsDDLXwB/Fp579ut+DKxJdxYT3DmUh7HtDLcl5lQ+KiISc7ojEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJuf8Pnne/HLhe9nsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "RocCurveDisplay(fpr=roc[0], tpr=roc[1]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "immune-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8062127612454735"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(dataset.labels_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-cliff",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-national",
   "metadata": {},
   "source": [
    "We will now compare the performance of the neural network to the baseline performance of logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "strategic-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Test Data: 0.8665427430768256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression().fit(dataset.train, dataset.labels_train)\n",
    "y_pred = log_reg.predict(dataset.test)\n",
    "\n",
    "print(\"Precision on Test Data: \" + str(precision_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "friendly-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on Test Data: 0.801183524402867\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall on Test Data: \" + str(recall_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "still-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8393980102408348\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(dataset.labels_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "enhanced-harvest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2825b23eb50>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEJCAYAAACUk1DVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAszklEQVR4nO3de7xVVb3//9ebzeYmyF1FwCBFDbVQUdHMH2kpWiewYyezksyki5cy751OmuWjTM2yTH+WJJiJZnXkGIn31EoFBS9gKEoKiHK/yX3vz/ePOTYstmvtPRfsDfvyfvaYD9Ycc4wxx1o712fNMcYcUxGBmZlZm53dADMzaxocEMzMDHBAMDOzxAHBzMwABwQzM0scEMzMDHBAMDPbaSRVSJom6b60f5ukOZKmp21ISpekGyTNlvSCpEMK6hgt6dW0jS5IP1TSi6nMDZJUX3scEMzMdp5vAi/XSrsoIoakbXpKOxEYlLYxwE0AknoAlwNHAIcDl0vqnsrcBJxVUG5EfY1pu11vxRpMrx4VMaB/5c5uhpXhlRc67ewmWBnW8S4bYn29v5LrcsJHd4klS6ty5X32hfWTI6Lkl7CkfsAngKuAb9dT3UhgfGR3Ej8lqZukPsBw4MGIWJrqfBAYIekxYNeIeCqljwdGAX+t6yQOCE3EgP6VPDO5/85uhpXhhD2H7OwmWBmejoe3u44lS6t4ZvJeufJW9Hm1Vz1ZfgZcDHSplX6VpO8BDwOXRsR6oC8wtyDPvJRWV/q8Iul1cpeRmVlOAVTn/B/QS9LUgm1MTT2SPgksjIhna53iMmB/4DCgB3DJDnprgK8QzMxyC4KNka/LCFgcEUNLHPsw8ClJJwEdgF0l/S4ivpCOr5f0W+DCtD8fKOxC6JfS5pN1GxWmP5bS+xXJXydfIZiZlaGMK4SSIuKyiOgXEQOAU4FHIuILaVyANCNoFPBSKjIROD3NNhoGrIiIBcBk4HhJ3dNg8vHA5HRspaRhqa7TgXvre2++QjAzyykIqhp3heg7JPUGBEwHvpbSJwEnAbOBNcAZABGxVNIPgCkp35U1A8zAN4DbgI5kg8l1DiiDA4KZWVmqadiAEBGPkXXzEBHHlsgTwNkljo0FxhZJnwocWE5bHBDMzHIKoKqBA0JT4oBgZlaGhr5CaEocEMzMcgpgYwt+yqQDgplZTkG4y8jMzICAqpYbDxwQzMzyyu5UbrkcEMzMchNVbNf6eE2aA4KZWU7ZoLIDgplZq5fdh+CAYGZmQLWvEMzMzFcIZmYGQCCqWvAi0Q4IZmZlcJeRmZkRiA1RsbOb0WgcEMzMcspuTHOXkZmZ4UFlMzMDIkRV+ArBzMyAal8hmJlZNqjccr82W+61j5lZA6sZVM6z5SGpQtI0Sfel/YGSnpY0W9Jdktql9PZpf3Y6PqCgjstS+ixJJxSkj0hpsyVdmqc9DghmZmWoCuXacvom8HLB/tXA9RGxD7AMODOlnwksS+nXp3xIGgycChwAjAB+lYJMBXAjcCIwGPhcylsnBwQzs5xq7lTOs9VHUj/gE8Bv0r6AY4F7UpZxwKj0emTaJx0/LuUfCUyIiPURMQeYDRyettkR8XpEbAAmpLx1armdYWZmjaA6/yyjXpKmFuzfEhG3FOz/DLgY6JL2ewLLI2JT2p8H9E2v+wJzASJik6QVKX9f4KmCOgvLzK2VfkR9DXZAMDPLKVvcLndAWBwRQ4sdkPRJYGFEPCtpeMO0bvs5IJiZ5RSIjQ2zdMWHgU9JOgnoAOwK/BzoJqltukroB8xP+ecD/YF5ktoCXYElBek1CsuUSi/JYwhmZjlFQFW0ybXVXU9cFhH9ImIA2aDwIxHxeeBR4JSUbTRwb3o9Me2Tjj8SEZHST02zkAYCg4BngCnAoDRrqV06x8T63p+vEMzMclNj35h2CTBB0g+BacCtKf1W4HZJs4GlZF/wRMQMSXcDM4FNwNkRUQUg6RxgMlABjI2IGfWd3AHBzCyngAZfuiIiHgMeS69fJ5shVDvPOuAzJcpfBVxVJH0SMKmctjggmJmVwQ/IMTMzAvkBOWZmlnUZbWzBaxm13HdmZtbg5OchmJlZWtzOz0MwMzPwE9PMzIzsiWm+QjAzszSo3CBLVzRJDghmZrn5mcpmZkbNoLLHEMzMDN+pbGZm+E5lMzMrUO0rBDMzi4CN1Q4IZmatXtZl5IBgRlUVnDtiX3r22cgPxs/h2m/txQv/3IVdulQDcOHP3mTvA9fyyJ+6c/eNuxEBHXep5twfz2XvA9YBMOXRLtz8P32pqhYnfm4Jnz13IUDJuqxh7LJrFedfO5cB+68jAn767f4cduxKjjxhJRGwfHFbrv3WXix9p5L++6zj2z+dyz4HrWXc1Xtwz827ba7n5LMWceJpS4gQc/7VgevO78/G9S33C7IY36m8DSQF8NOIuCDtXwh0jogr6igzCnglImYWOXYFcBawCNgFeBH4brG8tcrtD0wgmzF2SkS8Vub7uAJYHRHXSvoS8EBEvFVG+QHAfRFxYDnnbYr+9ze96T9oPWtWb/kCOOt/3uIjn1yxVb7d+6/nmj/Opku3KqY80oWfX9yfG/7yKlVVcON3+vGjCa/Rq89Gzj1pX4adsIL37bu+ZF3WML5+5XymPtaFH44ZQNvKatp3DN6Y1YHx1/QBYOSZi/jC+e9ww6X9WLmsgpv+py9Hjdj6b9Fzj42MOnMxZw3fjw3r2vDfN/+b4SOX8+DdPXbGW9opWvq008YM7euBT0vqVUaZUcDgOo5fHxFDImIQcBfwiKTeOeq8JyIOLjcYFPElYM/trKNZWvRWJc88vCsnnrak3rwHHLaGLt2qANj/kDUsXlAJwKxpndhzwHr6vG8Dle2C4SOX8c/JXRu13QadulRx0LB3uf/32Rf3po1teHdlBWtWb7njtkPHaiKy1yuWVPLK853YtOm9X3wVbYP2HappUxG071jNkncqd8h7aDqyLqM8W3PUmK3eBNwCnF/7gKQBkh6R9IKkhyXtJeko4FPANZKmS9q7rsoj4i7gAeC0VOehkv4m6VlJkyX1kXQS8C3g65IeTfn+N+WZIWlMQZtWF7w+RdJttdp8CjAUuCO1r2Oxcxa05XlJzwNnl/3JNUE3X96Xr3z3LVTr/zG3/bgPXztuP26+fE82rH/vF8j9d/bgsI+uAmDJ25X03nPj5mO9+mzcHCzy1GXbZo+9NrBiSQUXXD+XGx+YxbeunUv7jlnA/tIlC/jd1Jkc++nljL9mjzrrWfJ2Jffc1Jvbp7zMndNn8O6qCp77W5cd8RaalOr0XOX6tuaoscPYjcDnJdX+GfgLYFxEfBC4A7ghIv4BTAQuSlcBeX7NPwfsL6ky1XlKRBwKjAWuSs8UvZnsyuKjqcyXU56hwHmSeuZ5IxFxDzAV+HxEDCELeO85Z8r+W+DciPhQnrqbuqce3JVuvTYx6INb9+mfcdlb/OaJf3HDpFdYtbwtd9+421bHp/+9M5Pv7MmZ/11/D1t9ddm2q6gI9jloLfeN78nZx+/HujVt+Ow52djNbVf34QtDB/PIn7rxqS8vrrOezl03ceQJKxl9xAc47eAD6NCpmmM/vWxHvIUmI5tlVJFrq4+kDpKeST8eZ0j6fkq/TdKc9MNzuqQhKV2SbpA0O/2YPqSgrtGSXk3b6IL0QyW9mMrcIKnOSNWoASEiVgLjgfNqHToS+H16fTtw9DaeoubN7QccCDwoaTrwXaBfiTLnpV/uTwH9gUHbeO6i55TUDegWEY+nfLeXbLw0RtJUSVMXLanaxmY0vplTduGpB3bl9MMH86Ovv4/nn+zC1efsRc/dNyFBu/bB8Z9dyqzpnTaXeX1mB352YX+u+O0cdu2Rvbeee2xk0VtbrggWL6ikV5/siqGuumz7LF5QyaIFlcyatgsAT97XlX0O2jq4P/Ln7hx9Ut3jNwd/ZDVvz23HiqVtqdok/j6pK4OHvtto7W6Kam5My7PlsB44Nv1wHAKMkDQsHav5YTwkIqantBPJvq8GAWOAmwAk9QAuB44ADgcul9Q9lbmJbOy1ptyIuhq0Izq6fgacSTYQ3NAOBl4mCwwzCj7AgyLi+NqZJQ0HPgYcmf4I04AO6XAUZO1A/XKdsy4RcUtEDI2Iob17Nt0VFL/8nQXc8exMxj8zk8tueoMPHb2KS375JkveyeYkRMA/7u/KgP2ymUQL51Vy5VcGctENb9Bv7/Wb69lvyBrmz2nP22+2Y+MG8di93Rl2/EqAknXZ9lu2qJLFb7Wj397ZZzrkI6t589UO7Dlwy9/myBNWMHd2+zrrWTi/kg8c8i7tO1YDwZCjV/NmPWVaoobqMopMTVd1ZdqijiIjgfGp3FNAt9RNfQLwYEQsjYhlwINkwaUPsGtEPBURQfbjfFRdbWr0aacRsVTS3WRBYWxK/gdwKtmv588DT6T0VUCuTklJ/wkcD1wArAB6SzoyIv6ZupD2jYgZtYp1BZZFxJo0+2hYwbF3JH0AmAWcnNpSW2H7ZpU6p6Tlko6OiCfT+2uRrj7nfaxY0pYI2PuAtZx39QIA7rh+D1Ytq+CXl/UHsoHIX97/ChVt4eyr5vGd095PdZU4/tSlm7/4S9VlDePG7/blkl++SdvK4O0323Hd+f05/9p59Nt7PdXVsHB+O264JLuo7t57I7/466t06lJFVMOoryxmzPD9mDVtF574SzdunPwKVZvE7Jc68tff5epxbTHKnGXUS9LUgv1bIuKWwgySKoBngX2AGyPiaUlfB66S9D3gYeDSiFgP9AXmFhSfl9LqSp9XJL2kHXUfwnXAOQX75wK/lXQR2TTSM1L6BODXks6j+BTR8yV9gexq4yWyy61FsHnQ94Y0XtGW7MqkdkC4H/iapJfJvtCfKjh2KXBfas9UoHOR93EbcLOktWTdXqXOeQYwNk29faDOT6aZ+dBRq/nQUdmPmp/8ofgwz/nXzeX86+YWPXb4cas4/Lh/vSe9VF3WMF6f0ZFzT9x3q7QfnDWgaN5liyr5wtDik/1uv3YPbr+27sHnlq6MGUSLI2JoXRkiogoYkrqa/yzpQOAy4G2gHdnEnEuAK7e5wWVotIAQEZ0LXr8DdCrYfwM4tkiZv1Ni2mm6f+GKOs43HTimRLma1+vJ+uGKlb8HuKee8n8E/lhwuNQ5nwUKB5QvLtVuM2s+IsSmRphSGhHL00zIERFxbUpeL+m3wIVpfz7ZuGeNfiltPjC8VvpjKb1fkfwlNc/JsmZmO0lDDSpL6p2uDJDUEfg48K+C6esi6/N/KRWZCJyeZhsNA1ZExAJgMnC8pO5pMPl4YHI6tlLSsFTX6cC9dbXJS1eYmeXUwHcq9wHGpXGENsDdEXFfukerN9nElenA11L+ScBJwGxgDamrPY3T/gCYkvJdGRFL0+tvkHV1dwT+mraSHBDMzMrQUAEhIl4gmylZO/093ekpPShxo2tEjGXLpJ3C9Klk0+NzcUAwM8vJD8gxM7PNmuuyFHk4IJiZ5RQBm/yAHDMzg5a9/LUDgplZTh5DMDOzzcIBwczMwIPKZmZGNqjsLiMzMwNElWcZmZkZeAzBzMxo8LWMmhwHBDOzvCIbR2ipHBDMzMrgWUZmZkZ4UNnMzGq4y8jMzADPMjIzM7KrAwcEMzMDPO3UzMySljyG0HKHy83MGlggqqvb5NrqI6mDpGckPS9phqTvp/SBkp6WNFvSXZLapfT2aX92Oj6goK7LUvosSScUpI9IabMlXVpfmxwQzMzKEDm3HNYDx0bEh4AhwAhJw4CrgesjYh9gGXBmyn8msCylX5/yIWkwcCpwADAC+JWkCkkVwI3AicBg4HMpb0kOCGZmeaVB5TxbvVVlVqfdyrQFcCxwT0ofB4xKr0emfdLx4yQppU+IiPURMQeYDRyettkR8XpEbAAmpLwlOSCYmZUj/yVCL0lTC7YxtatKv+SnAwuBB4HXgOURsSllmQf0Ta/7AnMB0vEVQM/C9FplSqWX5EFlM7MylDHtdHFEDK27rqgChkjqBvwZ2H/7Wrd9SgYESb+gjq6wiDivUVpkZtZEBVBd3fDTTiNiuaRHgSOBbpLapquAfsD8lG0+0B+YJ6kt0BVYUpBeo7BMqfSi6rpCmJrzvZiZtQ4BNNB9CJJ6AxtTMOgIfJxsoPhR4BSyPv/RwL2pyMS0/890/JGICEkTgd9L+imwJzAIeAYQMEjSQLJAcCpwWl1tKhkQImJc4b6kThGxpry3bGbWsjTgfQh9gHFpNlAb4O6IuE/STGCCpB8C04BbU/5bgdslzQaWkn3BExEzJN0NzAQ2AWenrigknQNMBiqAsRExo64G1TuGIOnI1JDOwF6SPgR8NSK+Ud57NzNrARooIETEC8DBRdJfJ5shVDt9HfCZEnVdBVxVJH0SMClvm/LMMvoZcAJZXxUR8TxwTN4TmJm1HPmmnDbX9Y5yzTKKiLnZdNfNqhqnOWZmTVwLXroiT0CYK+koICRVAt8EXm7cZpmZNUEB0QizjJqKPF1GXwPOJruh4S2yW6zPbsQ2mZk1Ycq5NT/1XiFExGLg8zugLWZmTV8L7jKq9wpB0vsl/Z+kRZIWSrpX0vt3ROPMzJqcBlzdrqnJ02X0e+BusjmzewJ/AO5szEaZmTVJNTem5dmaoTwBoVNE3B4Rm9L2O6BDYzfMzKwpyh6jWf/WHNW1llGP9PKv6cEKE8ji42cp40YHM7MWpQXPMqprUPlZsgBQ8+6/WnAsgMsaq1FmZk2Vmumv/zzqWsto4I5siJlZk9eMB4zzyHWnsqQDyR7BtnnsICLGN1ajzMyapuY7YJxHnsXtLgeGkwWESWTP53wScEAws9anBV8h5JlldApwHPB2RJwBfIjswQxmZq1Pdc6tGcrTZbQ2IqolbZK0K9mzP/vXV8jMrMVpwAfkNEV5AsLU9LzPX5PNPFpN9sQeM7NWp1XOMqpR8CCcmyXdD+yaHuxgZtb6tMaAIOmQuo5FxHON0yQzM9sZ6rpCuK6OYwEc28BtadVendWNTxw9amc3w8pwwey/7OwmWBnOG7m2QepplV1GEfHRHdkQM7MmL2iwpSsk9Sebvr97qvmWiPi5pCuAs4BFKet30rORkXQZcCbZUyvPi4jJKX0E8HOgAvhNRPw4pQ8kW3aoJ9kY8BcjYkOpNuWZdmpmZjUabvnrTcAFETEYGAacLWlwOnZ9RAxJW00wGAycChwAjAB+JalCUgVwI9k9YoOBzxXUc3Wqax9gGVkwKckBwcysDIp8W30iYkHNWGxErCJ7NHHfOoqMBCZExPqImAPMBg5P2+yIeD39+p8AjJQksq79e1L5ccCoutrkgGBmVo78Vwi9JE0t2MaUqlLSAOBg4OmUdI6kFySNldQ9pfUF5hYUm5fSSqX3BJZHxKZa6SXleWKaJH1B0vfS/l6SDq+vnJlZi5Q/ICyOiKEF2y3FqpPUGfgj8K2IWAncBOxN9vz6BdQ9wadB5blC+BVwJPC5tL+KrL/KzKxVydtdlHcmkqRKsmBwR0T8CSAi3omIqoioJrshuOYH+Hy2XiWiX0orlb4E6Capba30kvIEhCMi4mxgXWrsMqBdjnJmZi1PtfJt9Uh9/LcCL0fETwvS+xRkOxl4Kb2eCJwqqX2aPTQIeAaYAgySNFBSO7KB54kREcCjZOvRAYwG7q2rTXmWrtiYRrEjNbY3zXbpJjOz7dOA9yF8GPgi8KKk6SntO2SzhIaQfef+m/RwsoiYIeluYCbZDKWzI6IKQNI5wGSyaadjI2JGqu8SYIKkHwLTyAJQSXkCwg3An4HdJF1FFm2+m6OcmVnL00ABISKeZMsTKQuVfERxRFwFXFUkfVKxchHxOlu6nOqVZy2jOyQ9S7YEtoBREfFy3hOYmbUYZYwPNEd5HpCzF7AG+L/CtIh4szEbZmbWJLXmgAD8hewjENkjNAcCs8juljMza1XUgkdQ83QZHVS4n1ZB/UaJ7GZm1kzluULYSkQ8J+mIxmiMmVmT15q7jCR9u2C3DXAI8FajtcjMrKlq7YPKQJeC15vIxhT+2DjNMTNr4lprQEg3pHWJiAt3UHvMzJq21hgQJLWNiE2SPrwjG2Rm1lSJ1jvL6Bmy8YLpkiYCfwDerTlYsxCTmVmr4TEEOpCtmncsW+5HCMABwcxan1YaEHZLM4xeYksgqNGCPxIzszq04G+/ugJCBdCZ4osvteCPxMystNbaZbQgIq7cYS0xM2sOWmlAqP8JD2ZmrUm03llGx+2wVpiZNRet8QohIpbuyIaYmTUHrXUMwczManNAMDMzghYdENrs7AaYmTUXIusyyrPVW5fUX9KjkmZKmiHpmym9h6QHJb2a/u2e0iXpBkmzJb2Qnk1TU9folP9VSaML0g+V9GIqc4OkOicLOSCYmZWhoQIC2erRF0TEYGAYcLakwcClwMMRMQh4OO0DnAgMStsY4CbIAghwOXAEcDhweU0QSXnOKig3oq4GOSCYmZUjcm71VROxICKeS69XAS8DfYGRwLiUbRwwKr0eCYyPzFNAN0l9gBOAByNiaUQsAx4ERqRju0bEUxERwPiCuoryGIKZWTnyjyH0kjS1YP+WiLilWEZJA4CDgaeB3SNiQTr0NrB7et0XmFtQbF5Kqyt9XpH0khwQzMzyKm+108URMbS+TJI6kz107FsRsbKwmz8iQtpxE13dZWRmVo4G6jICkFRJFgzuKHikwDupu4f078KUPh/oX1C8X0qrK71fkfSSHBDMzMqg6nxbvfVklwK3Ai9HxE8LDk0EamYKjQbuLUg/Pc02GgasSF1Lk4HjJXVPg8nHA5PTsZWShqVznV5QV1HuMjIzK0MDduB8GPgi8KKk6SntO8CPgbslnQm8AfxXOjYJOAmYDawBzoBsVQlJPwCmpHxXFqw08Q3gNqAj8Ne0leSAYGaWVwPemBYRT1J6EdH3rCWXZgqdXaKuscDYIulTgQPztskBwcysHC34TmUHBDOznGruVG6pHBDMzMqg6pYbERwQzMzyauGL2zkgmJmVwV1GZmaWcUAwMzPwFYKZmdVwQDAzMyLfshTNlQOCmVlOvg/BzMy2iJYbERwQzMzK4CsEa9W+edk0Dj/qbZYva8/Zpx+73fUdN+JNPjv6FQDuGrcvD9+/11bHv/fjp9l9z3cb5FytXXUV/G7U++myxyZO/vWbTBvfg+du68HyN9vz9Wf+RaceVUD2o/fRH+zBnMc607ZjMOLq+ex+4DoWzuzAQ9/rw4bVbVAFHPGNRez/iZUATL50T955qSMR0H3Aekb85C3a7dKCO9ihxd+Y1qyehyCpStJ0STMkPS/pAkn1vgdJ16Qy12zjeVenfwdIOm0byt8m6ZRtOXdT8NCk/nzvgiPLLvejXzzJbnus2Sqtc5cNnPblWXx7zDF8e8wxnPblWXTusmHz8aOOeYu1ayu2u82Wee62nvTcZ/3m/T0PXcMp499g174btso352+dWfbvdnz54dl8/Idv8dDlfQBo27GaE6+dz5fuf43/HPsGj/1wD9atzP6TG/7fb3P6fa8x+i+vseueG5l2e48d98Z2ooZ6HkJT1KwCArA2IoZExAHAx4ETgctzlBsDfDAiLtrO8w8Ayg4Izd2M53uxamW7rdL22PNdrrzun/z81se4+sYn6LfXqlx1HXrEQqZN6c3qVe1Yvaod06b05tAjsgdCdei4iVGnvsaEcfs2+HtojVYtaMucxzpz0H8t35y2+wHr6Npv43vyvvZQFwafvBwJ9jx4LetXVrB6YVt6DNxA9wFZ8Oi8+yY69axi7dKsY6F9l+xbLwI2rW+DSi3k3MI4IDRBEbGQ7Iv+nPQEoYp0JTBF0guSvgogaSLQGXhW0mcl/YekpyVNk/SQpN1TviskXVhTv6SX0oOvC/0Y+Ei6Sjm/jnNK0i8lzZL0ELBb438iO9a5F0/n5usP4ptnDmfsjQfwjQteyFWuZ+91LFrYcfP+4oUd6dl7HQBf/MrL/HnC3qxf557MhvDoD/fgmEveIc8jeVe/U0mXPps273fZYyOr39n677Dg+Y5UbRTd9tpydXH/JXty87D9WPpaew4+fUnDNb6pCrIImGdrhpr1f3kR8bqkCrIv3JFkj5Q7TFJ74O+SHoiIT0laHRFDANIj5oalh1d/BbgYuCDnKS8FLoyIT6a6xhQ7J3AwsB8wGNgdmEmRh1ek8mMAOrTtso2fwo7XoeMmPnDQUi77wZTNaZWV2U+ij530BiM/8zoAffq+y/ev+SebNrXh7QWduOo7R5Ss8/37rKBP3zX8+hcHvaebycr32iOd6dSzit0PXMfcpzptd32rF7blrxf2ZcRP5lPYSTvi6reoroJHvt+HWX/pyoGnLN/uczV1HlRuHo4HPljQV98VGATMqZWvH3BXenh1uyLHG+KcxwB3RkQV8JakR4oVjohbgFsAunbYo9n830wK3l1VyblnfPQ9xx6a9D4emvQ+IBtDuP6qQ1j49pYvpCWLOnDQwYs37/fabS0vTuvF/gcuZZ/9lzH2Dw9QURF07b6eH/3iSS479+jGf0Mt0FvPduK1h7sw52+d2bRebFhdwaRv9+WknxZ/xnrn3TeyasGWr4NVb1fSeffsimH9qjb8+St7cfS3F7LnwWvfU7ZNBez/yRVM+XWvVhEQWvKgcrMOCJLeD1QBC8nuGTk3IibXU+wXwE8jYqKk4cAVKX0TW3ehdcjThGLnlHRSjrLN1to1lbyzoBNHf3Q+Tz7aFwgG7rOSObO71lv22ad34/QxL28eSD74sEXcdvNgVq9qx6T/HQjAbnus4fKfPOVgsB0+ctFCPnJRNjYz96lOTL21V8lgALD3cauYdnsP9v/kShZM70j7LlV03m0TVRvExG/0Z/DJy9n3xJWb80fA8jfa0X3ABiJg9sNd6P7+9SXrbyl8Y1oTJak3cDPwy9T9Mxn4uqRHImKjpH2B+RHxbq2iXYGa/zJGF6T/G6jpCjoEGFjktKuAwr6doucEHge+KmkcWXfWR4Hfb8fb3akuvmIqBw1ZzK7dNjDuT5O549b9uebKQzn7whf47OhXaFtRzeMP98sVEFavaseEcfty/a8fB+DO2/Zl9ap29ZSyhvLcuB5MuaUX7y5uy/hP7s3A/281J/zoLQYOX83rj3Xh1mMHUdmxmhOuzv4TmTVpV+ZN2YW1yyuY8aduQNZN1Hv/ddx/cV82rG5DBPT+wDo+9v0FO/Gd7SARDfaAHEljyb5zFkbEgSntCuAsYFHK9p2ImJSOXQacSfYj+LyaH6KSRgA/ByqA30TEj1P6QGAC0BN4FvhiRGw9vax2m6IZDX5IqgJeBCrJftHfTvZrvzpNP/0h8B9kgXwRMCoiVqQxhM6pjpHA9cAy4BHgsIgYLqkjcC/QF3gaOBI4MSL+XVNeUiVZEOgJ3Eb2R3jPOYGVZFciHwfeBDYCYyPinlLvrWuHPeKofl9smA/KdohvPvCXnd0EK8N5I+fwyotrt2suVJdu/eLgY76ZK+8T/3fxsxExtNRxSccAq4HxtQLC6oi4tlbewcCdwOHAnsBDQM10vFfIvmvmAVOAz0XETEl3A3+KiAmSbgaej4ib6mpzs7pCiIiSE9Qjohr4TtpqH+tc8Ppesi/+2nnWko0JFKu7c/p3I1D7bqmi5wTOKdVWM2u+GqrLKCIeLzKTsZSRwISIWA/MkTSbLDgAzI6I1wEkTQBGSnqZ7LuqZpr8OLLu8ToDQrOddmpmtsMFUB35NuglaWrBNibnWc5J09jHplmRkPVczC3IMy+llUrvCSyPiE210uvkgGBmVo7IucHiiBhasN2So/abgL2BIcAC4LqGbn5dmlWXkZnZztaYs4wi4p3N55F+DdyXducD/Quy9mPL5Jhi6UuAbpLapquEwvwl+QrBzKwMqo5c2zbVnd0fVeNk4KX0eiJwqqT2afbQIOAZskHkQZIGSmoHnApMjGy20KNAzT1SoykydlqbrxDMzPJqwNVOJd0JDCcba5hHti7bcElD0ln+DXwVICJmpFlDM8lmWJ6dbnxF0jlksx8ryGYzzkinuASYIOmHwDTg1vra5IBgZpZTdmNaw0SEiPhckeSSX9oRcRVwVZH0ScCkIumvs2UmUi4OCGZm5WimK5nm4YBgZlaGhrpCaIocEMzM8mrhT0xzQDAzy63h1jJqihwQzMzK4S4jMzMjmu/jMfNwQDAzK4evEMzMDPCgspmZZVTdcvuMHBDMzPIKfGOamZmBCN+YZmZmiQOCmZkBDghmZobHEMzMbAvPMjIzMyDcZWRmZqTVTh0QzMwMPIZgZmaZlnwfQpud3QAzs2YlIt9WD0ljJS2U9FJBWg9JD0p6Nf3bPaVL0g2SZkt6QdIhBWVGp/yvShpdkH6opBdTmRskqb42OSCYmeUVAVXV+bb63QaMqJV2KfBwRAwCHk77ACcCg9I2BrgJsgACXA4cARwOXF4TRFKeswrK1T7XezggmJmVo4GuECLicWBpreSRwLj0ehwwqiB9fGSeArpJ6gOcADwYEUsjYhnwIDAiHds1Ip6KiADGF9RVkscQzMzKkX8MoZekqQX7t0TELfWU2T0iFqTXbwO7p9d9gbkF+ealtLrS5xVJr5MDgplZXgHkf6by4ogYus2nighJO3QE211GZma5BUR1vm3bvJO6e0j/Lkzp84H+Bfn6pbS60vsVSa+TA4KZWV5BQw4qFzMRqJkpNBq4tyD99DTbaBiwInUtTQaOl9Q9DSYfD0xOx1ZKGpZmF51eUFdJ7jIyMytHA92HIOlOYDjZWMM8stlCPwbulnQm8AbwXyn7JOAkYDawBjgja0oslfQDYErKd2VE1AxUf4NsJlNH4K9pq5MDgplZORooIETE50ocOq5I3gDOLlHPWGBskfSpwIHltMkBwcwsNy9uZ2ZmkGYZtdzFjBwQzMzK4SsEMzOD2J4ZRE2eA4KZWV4Bse33GDR5DghmZuXIf6dys+OAYGZWDo8hmJkZEZ5lZGZmia8QzMwMgqiq2tmNaDQOCGZmeZW3/HWz44BgZlYOTzs1M7MAwlcIZmaWPS/ZVwhmZgYtelBZ0YKnUDUnkhaRPRCjpekFLN7ZjbCytNS/2fsiovf2VCDpfrLPJ4/FETFie863ozkgWKOSNHV7HjRuO57/Zq2Xn6lsZmaAA4KZmSUOCNbYbtnZDbCy+W/WSnkMwczMAF8hmJlZ4oDQQkkKSdcV7F8o6Yp6yoySNLjEsSskzZc0XdKrkv5UKm+tcvunMtMk7b0N7+MKSRem11+StGeZ5QdIeqnc8zZlkqrSZzpD0vOSLpBU73/Lkq5JZa7ZxvOuTv8OkHTaNpS/TdIp23Ju2zEcEFqu9cCnJeWdMw0wCqjrS/76iBgSEYOAu4BHJNU3r3sUcE9EHBwRr5XRlmK+BJQVEFqotenvcADwceBE4PIc5cYAH4yIi7bz/AOAsgOCNX0OCC3XJrLBwfNrH0i/8B6R9IKkhyXtJeko4FPANenXZ52/5iPiLuAB0heDpEMl/U3Ss5ImS+oj6STgW8DXJT2a8v1vyjND0piCNq0ueH2KpNtqtfkUYChwR2pfx2LnLGjL85KeB84u+5NrRiJiIdkX/TnKVKQrgSnp7/tVAEkTgc7As5I+K+k/JD2drtwekrR7yrf5iiztvyRpQK3T/hj4SPo7nF/HOSXpl5JmSXoI2K3xPxHbHg4ILduNwOclda2V/gtgXER8ELgDuCEi/gFMBC5Kvz7z/Jp/DthfUmWq85SIOBQYC1wVEZOAm8muLD6aynw55RkKnCepZ543EhH3AFOBz0fEELKA955zpuy/Bc6NiA/lqbu5i4jXgQqyL9wzgRURcRhwGHCWpIER8Sm2XFncBTwJDIuIg4EJwMVlnPJS4IlU1/WlzgmcDOxHdtV5OnBUQ7xfazxey6gFi4iVksYD5wFrCw4dCXw6vb4d+Mk2nkLp3/2AA4EHJUH25bSgRJnzJJ2cXvcHBgFLtuHcRc8pqRvQLSIeT/luJ+tSaS2OBz5Y0FfflewznlMrXz/grnRV1a7I8YY45zHAnRFRBbwl6ZHtOIftAA4ILd/PyH7J/7YR6j6Y7Fe7gBkRcWRdmSUNBz4GHBkRayQ9BnRIhwvnP3egfkXPmQJCqyLp/UAVsJDsczk3IibXU+wXwE8jYmL6u1yR0jexdc9B3r/Fe86ZugytGXGXUQsXEUuBu8ku62v8Azg1vf488ER6vQrokqdeSf9J9svwTmAW0FvSkelYpaQDihTrCixLwWB/YFjBsXckfSDNljm5SNna7St6zohYDiyXdHTB+2ux0qD+zcAvI7upaDLZmE1lOr6vpF2KFO0KzE+vRxek/xs4JJU9BBhYpGzt/5+UOufjwGfTGEMf4KPvrcqaEgeE1uE6tl6h8VzgDEkvAF8EvpnSJwAXqfQU0fPTQOKrwBeAYyNiUURsAE4Brk4DudMp3l98P9BW0stkA5NPFRy7FLiPLFiV6m66DbhZ0nSyLqJS5zwDuDHl03tqaf46pr/DDOAhssH976djvwFmAs8pm277/1O8J+AK4A+SnmXrlU3/CPRIdZ8DvFKk7AtAVRq4P7+Oc/4ZeDUdGw/8c9vfsu0IvlPZzMwAXyGYmVnigGBmZoADgpmZJQ4IZmYGOCCYmVnigGDNgras8PmSpD9I6rQddW1edVPSb1THqq2Shitb56ncc/xbRRYWLJVeK8/quo4Xyb/V+kNm28oBwZqLmnV4DgQ2AF8rPChpm+66j4ivRMTMOrIMx2vwWCvhgGDN0RPAPunX+xNpJc+Z27LqpqTHJA1Nr0dIei7dcPVwWuXza2y5Ie8jknpL+mM6xxRJH05le0p6QNkqrr8hxw1xKrHyazp2fUp/ON2NjKS9Jd2fyjyR7vY2azBey8ialXQlcCLZXc+QLbNwYETMSV+qKyLiMEntgb9LeoBszaWaVTd3J7tzdmytensDvwaOSXX1iIilkm4GVkfEtSnf78lWb31S0l5kyzZ8gOx5BE9GxJWSPsHWS4WU8uV0jo7AFEl/jIglwC7A1Ig4X9L3Ut3nkC1n/rWIeFXSEcCvgGO34WM0K8oBwZqLjmkpCsiuEG4l68p5JiJqVurcnlU3hwGP19SV1oAq5mPAYGnzBcCukjqnc3w6lf2LpGU53lOplV+ryR5ABPA74E/pHEeRLTdRU759jnOY5eaAYM3F2vQchM3SF+O7hUk0/qqbbcieI7CuSFtyU90rv9YW6bzLa38GZg3JYwjWkmzPqptPAccoe7ALknqk9Norez5AtjggKd+Q9PJxtjw97kSgez1trWvl1zZkC/eR6nwyIlYCcyR9Jp1DklrFA4Bsx3FAsJZkm1fdjIhFZI+i/FNaPbWmy+b/gJNrBpXJHjY0NA1az2TLbKfvkwWUGWRdR2/W09a6Vn59Fzg8vYdjgStT+ueBM1P7ZgAjc3wmZrl5tVMzMwN8hWBmZokDgpmZAQ4IZmaWOCCYmRnggGBmZokDgpmZAQ4IZmaWOCCYmRkA/w/PJEk0vP/J2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(dataset.labels_test, y_pred), display_labels=[\"Not Defaulted\", \"Defaulted\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "above-label",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x282651a8df0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc = roc_curve(dataset.labels_test, y_pred)\n",
    "RocCurveDisplay(fpr=roc[0], tpr=roc[1]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "athletic-yesterday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8392793386236138"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(dataset.labels_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-course",
   "metadata": {},
   "source": [
    "# XAI Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "challenging-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(dataset.class_names, dataset.feature_names,\n",
    "                                                  dataset.train, dataset.categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "valid-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for outputting a flattened version of neural network predictions for use in explainer\n",
    "def predict_and_flatten(X):\n",
    "    y = gs.predict(X)\n",
    "    y = y.flatten()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-appendix",
   "metadata": {},
   "source": [
    "Lets look at a few examples of anchors generated using our two different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "deluxe-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.97\n",
      "Coverage: 0.49\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print('Neural Network Prediction: ', explainer.class_names[int(gs.predict(dataset.test[0]))])\n",
    "exp = explainer.explain_instance(dataset.test[0], predict_and_flatten, threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "governmental-dakota",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No AND creditScore <= 0.08\n",
      "Precision: 0.96\n",
      "Coverage: 0.49\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Prediction: ', explainer.class_names[int(log_reg.predict(dataset.test[0].reshape(1, -1)))])\n",
    "exp = explainer.explain_instance(dataset.test[0], log_reg.predict, threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cordless-porcelain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.18 AND creditScore <= 0.07 AND Stated, Verified Employment = No\n",
      "Precision: 0.96\n",
      "Coverage: 0.45\n"
     ]
    }
   ],
   "source": [
    "print('Neural Network Prediction: ', explainer.class_names[int(gs.predict(dataset.test[25]))])\n",
    "exp = explainer.explain_instance(dataset.test[25], predict_and_flatten, threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "breathing-guest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.51 AND Scheduled Payment Amount <= 0.08 AND vehicleValueAmount > 0.07\n",
      "Precision: 0.96\n",
      "Coverage: 0.09\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Prediction: ', explainer.class_names[int(log_reg.predict(dataset.test[25].reshape(1, -1)))])\n",
    "exp = explainer.explain_instance(dataset.test[25], log_reg.predict, threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-burns",
   "metadata": {},
   "source": [
    "Here are some more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "concerned-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.98\n",
      "Coverage: 0.49\n",
      "1 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND rateSubvention = No\n",
      "Precision: 0.99\n",
      "Coverage: 0.24\n",
      "2 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.98\n",
      "Coverage: 0.50\n",
      "3 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: rateSubvention = Yes AND interestRate <= 0.51\n",
      "Precision: 1.00\n",
      "Coverage: 0.18\n",
      "4 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18 AND rateSubvention = Yes\n",
      "Precision: 1.00\n",
      "Coverage: 0.16\n",
      "5 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18 AND paymentToIncomePercentage = 0.0\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n",
      "6 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: rateSubvention = Yes AND interestRate <= 0.51\n",
      "Precision: 1.00\n",
      "Coverage: 0.17\n",
      "7 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.18 AND rateSubvention = No AND creditScore <= 0.08 AND 0.72 < originalLoanTerm <= 0.79\n",
      "Precision: 0.97\n",
      "Coverage: 0.45\n",
      "8 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18 AND rateSubvention = Yes\n",
      "Precision: 1.00\n",
      "Coverage: 0.16\n",
      "9 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.97\n",
      "Coverage: 0.49\n",
      "10 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 0.95\n",
      "Coverage: 0.24\n",
      "11 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 0.95\n",
      "Coverage: 0.25\n",
      "12 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND rateSubvention = No\n",
      "Precision: 0.99\n",
      "Coverage: 0.24\n",
      "13 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 0.95\n",
      "Coverage: 0.25\n",
      "14 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.97\n",
      "Coverage: 0.49\n",
      "15 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND creditScore <= 0.07\n",
      "Precision: 0.98\n",
      "Coverage: 0.42\n",
      "16 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.18 AND vehicleValueAmount <= 0.07 AND originalLoanTerm > 0.72 AND underwritingIndicator = 1.0 AND creditScore <= 0.08\n",
      "Precision: 0.96\n",
      "Coverage: 0.16\n",
      "17 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND rateSubvention = No\n",
      "Precision: 0.99\n",
      "Coverage: 0.23\n",
      "18 Neural Network Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No\n",
      "Precision: 0.97\n",
      "Coverage: 0.49\n",
      "19 Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18 AND rateSubvention = Yes\n",
      "Precision: 1.00\n",
      "Coverage: 0.16\n",
      "20 Neural Network Prediction:  Defaulted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-2a077b8dbbf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Neural Network Prediction: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_and_flatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Anchor: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' AND '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m             data_row, classifier_fn, desired_label=desired_label)\n\u001b[0;32m    277\u001b[0m         \u001b[1;31m# return sample_fn, mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         exp = anchor_base.AnchorBaseBeam.anchor_beam(\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0msample_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36manchor_beam\u001b[1;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[0;32m    312\u001b[0m                                                                   state)\n\u001b[0;32m    313\u001b[0m             \u001b[1;31m# print tuples, beam_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             chosen_tuples = AnchorBaseBeam.lucb(\n\u001b[0m\u001b[0;32m    315\u001b[0m                 \u001b[0msample_fns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_stats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36mlucb\u001b[1;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(n, t)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0msample_fns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36mcomplete_sample_fn\u001b[1;34m(t, n)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0msample_fns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mcurrent_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# idxs = range(state['data'].shape[0], state['data'].shape[0] + n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36msample_fn\u001b[1;34m(present, num_samples, compute_labels)\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# conditions_eq = dict([(x, data_row[x]) for x in present])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             raw_data = self.sample_from_train(\n\u001b[0m\u001b[0;32m    251\u001b[0m                 conditions_eq, {}, conditions_geq, conditions_leq, num_samples)\n\u001b[0;32m    252\u001b[0m             \u001b[0md_raw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscretize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36msample_from_train\u001b[1;34m(self, conditions_eq, conditions_neq, conditions_geq, conditions_leq, num_samples)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconditions_leq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mconditions_leq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(len(dataset.test)):\n",
    "    print(str(idx) + ' Neural Network Prediction: ', explainer.class_names[int(gs.predict(dataset.test[idx]))])\n",
    "    exp = explainer.explain_instance(dataset.test[idx], predict_and_flatten, threshold=0.95)\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "    print('Precision: %.2f' % exp.precision())\n",
    "    print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "prospective-ideal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND rateSubvention = No AND incomeVerifiedIndicator = -1 AND creditScore <= 0.08\n",
      "Precision: 0.98\n",
      "Coverage: 0.41\n",
      "1 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND rateSubvention = No\n",
      "Precision: 0.97\n",
      "Coverage: 0.24\n",
      "2 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND usedIndicator = Used Vehicle AND Stated, Verified Employment = No\n",
      "Precision: 0.96\n",
      "Coverage: 0.33\n",
      "3 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.51 AND cashRebateSubvention = Yes\n",
      "Precision: 1.00\n",
      "Coverage: 0.10\n",
      "4 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 0.99\n",
      "Coverage: 0.25\n",
      "5 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "6 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.51 AND rateSubvention = Yes\n",
      "Precision: 1.00\n",
      "Coverage: 0.17\n",
      "7 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.18 AND creditScore <= 0.08 AND 0.72 < originalLoanTerm <= 0.79 AND incomeVerifiedIndicator = -1 AND vehicleValueAmount <= 0.12 AND Scheduled Payment Amount > 0.08 AND SUV = No\n",
      "Precision: 0.95\n",
      "Coverage: 0.19\n",
      "8 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "9 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND creditScore <= 0.07 AND incomeVerifiedIndicator = -1\n",
      "Precision: 0.99\n",
      "Coverage: 0.35\n",
      "10 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "11 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "12 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND vehicleValueAmount <= 0.09\n",
      "Precision: 0.97\n",
      "Coverage: 0.19\n",
      "13 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "14 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND creditScore <= 0.07 AND Stated, Verified Employment = No\n",
      "Precision: 0.98\n",
      "Coverage: 0.38\n",
      "15 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND vehicleValueAmount <= 0.07\n",
      "Precision: 0.97\n",
      "Coverage: 0.19\n",
      "16 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.18 AND vehicleValueAmount <= 0.07 AND originalLoanTerm > 0.72 AND incomeVerifiedIndicator = -1 AND originalLoanAmount <= 0.06 AND creditScore <= 0.08 AND underwritingIndicator = 1.0\n",
      "Precision: 0.96\n",
      "Coverage: 0.11\n",
      "17 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.69 AND cashRebateSubvention = No\n",
      "Precision: 0.96\n",
      "Coverage: 0.24\n",
      "18 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND vehicleValueAmount <= 0.07\n",
      "Precision: 0.95\n",
      "Coverage: 0.19\n",
      "19 Logistic Regression Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.18\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "20 Logistic Regression Prediction:  Defaulted\n",
      "Anchor: interestRate > 0.51 AND vehicleValueAmount <= 0.07 AND Stated, Verified Employment = No\n",
      "Precision: 0.98\n",
      "Coverage: 0.17\n",
      "21 Logistic Regression Prediction:  Not Defaulted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e458d2352487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Logistic Regression Prediction: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Anchor: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' AND '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m             data_row, classifier_fn, desired_label=desired_label)\n\u001b[0;32m    277\u001b[0m         \u001b[1;31m# return sample_fn, mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         exp = anchor_base.AnchorBaseBeam.anchor_beam(\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0msample_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36manchor_beam\u001b[1;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[0;32m    312\u001b[0m                                                                   state)\n\u001b[0;32m    313\u001b[0m             \u001b[1;31m# print tuples, beam_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             chosen_tuples = AnchorBaseBeam.lucb(\n\u001b[0m\u001b[0;32m    315\u001b[0m                 \u001b[0msample_fns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_stats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36mlucb\u001b[1;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mut\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(n, t)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0msample_fns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_base.py\u001b[0m in \u001b[0;36mcomplete_sample_fn\u001b[1;34m(t, n)\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0msample_fns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mcurrent_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;31m# idxs = range(state['data'].shape[0], state['data'].shape[0] + n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36msample_fn\u001b[1;34m(present, num_samples, compute_labels)\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# conditions_eq = dict([(x, data_row[x]) for x in present])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             raw_data = self.sample_from_train(\n\u001b[0m\u001b[0;32m    251\u001b[0m                 conditions_eq, {}, conditions_geq, conditions_leq, num_samples)\n\u001b[0;32m    252\u001b[0m             \u001b[0md_raw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscretize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36msample_from_train\u001b[1;34m(self, conditions_eq, conditions_neq, conditions_geq, conditions_leq, num_samples)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mconditions_geq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconditions_leq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mconditions_leq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(len(dataset.test)):\n",
    "    print(str(idx) + ' Logistic Regression Prediction: ', explainer.class_names[int(log_reg.predict(dataset.test[idx].reshape(1, -1)))])\n",
    "    exp = explainer.explain_instance(dataset.test[idx], log_reg.predict, threshold=0.95)\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "    print('Precision: %.2f' % exp.precision())\n",
    "    print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-shadow",
   "metadata": {},
   "source": [
    "Lets compare this explanation with the logistic regression log odds to see if this aligns with the XAI interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cardiac-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "originalLoanAmount coefficient: -4.306865049187424\n",
      "originalLoanAmount odds: 0.013475729192399529\n",
      "originalLoanTerm coefficient: -0.6840838991230576\n",
      "originalLoanTerm odds: 0.5045522386673531\n",
      "Scheduled Payment Amount coefficient: -8.665094988705706\n",
      "Scheduled Payment Amount odds: 0.0001725031624347721\n",
      "interestRate coefficient: -5.829609679194432\n",
      "interestRate odds: 0.002939223996634915\n",
      "creditScore coefficient: 5.341994303235848\n",
      "creditScore odds: 208.92896279083527\n",
      "incomeVerifiedIndicator coefficient: 2.0098013599304796\n",
      "incomeVerifiedIndicator odds: 7.461834980676051\n",
      "usedIndicator coefficient: 0.5622927982100091\n",
      "usedIndicator odds: 1.7546910441657564\n",
      "underwritingIndicator coefficient: -0.7675286708471938\n",
      "underwritingIndicator odds: 0.46415874108924726\n",
      "gracePeriodNumber coefficient: 0.1788520814508661\n",
      "gracePeriodNumber odds: 1.1958438435984324\n",
      "vehicleValueAmount coefficient: 14.826051214888576\n",
      "vehicleValueAmount odds: 2747085.8445725767\n",
      "coObligorIndicator coefficient: 0.10027485523939657\n",
      "coObligorIndicator odds: 1.1054747218420253\n",
      "paymentToIncomePercentage coefficient: -0.36286286624983366\n",
      "paymentToIncomePercentage odds: 0.6956818284160675\n",
      "assetAddedIndicator coefficient: 6.364809414481381\n",
      "assetAddedIndicator odds: 581.0340810822698\n",
      "rateSubvention coefficient: 0.6422814630180405\n",
      "rateSubvention odds: 1.9008125697123444\n",
      "cashRebateSubvention coefficient: 1.7095896087680151\n",
      "cashRebateSubvention odds: 5.5266929058444285\n",
      "otherSubvention coefficient: 0.36225943204189065\n",
      "otherSubvention odds: 1.4365715863202795\n",
      "Not stated, Not Verified Employment coefficient: -0.26047790745810234\n",
      "Not stated, Not Verified Employment odds: 0.7706831825384749\n",
      "Stated, Not Verified Employment coefficient: 0.33941266709682316\n",
      "Stated, Not Verified Employment odds: 1.4041226608942996\n",
      "Stated, Verified Employment coefficient: 1.000384773007627\n",
      "Stated, Verified Employment odds: 2.7193279511807456\n",
      "Car coefficient: 0.23587659533592498\n",
      "Car odds: 1.2660180679921782\n",
      "Truck coefficient: 0.2668139219949895\n",
      "Truck odds: 1.3057974435393767\n",
      "SUV coefficient: 0.5766290153154043\n",
      "SUV odds: 1.7800278590183212\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i in range(len(explainer.feature_names)):\n",
    "    print(str(explainer.feature_names[i]) + \" coefficient: \" + str((log_reg.coef_[0][i])))  \n",
    "    print(str(explainer.feature_names[i]) + \" odds: \" + str(math.exp(log_reg.coef_[0][i])))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-boxing",
   "metadata": {},
   "source": [
    "We see different results than the XAI framework. It is a bit harder to interpret due to the data being min-max normalized, but all else being equal, the odds of default from 1 point change in normalized interest rate (i.e. the difference between the max and min actual interest rate) is changed by a factor of 0.0029. \n",
    "\n",
    "Put differently, this means that all else being equal, a 1 point change in normalized interest rate results in a \n",
    "1 - 0.0029 = 99.71% decrease in the odds of default.\n",
    "\n",
    "What this means is that, counter to the XAI framework, the logistic regression model infers an inverse relationship between interest rate and probability of default. This is counter-intuitive to a conceptual understanding of high interest rates reflecting high risk, and thus high likelihood of default. This can be further investigated by finding the p value for this coefficient to determine if that coefficient is statistically significant. The issue with this model may be that the features of \"credit score\", \"interest rate\", \"monthly payment\" and \"term\" might be highly correlated, which may mean that the effects of the other variables on interest rate could cause this inverse relationship to appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "forty-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.27339708e-03,  5.74474875e-03, -4.38538226e-05,  7.58879597e-02,\n",
       "       -4.14145162e-03,  8.12256600e-03,  5.47270116e-02,  1.84442720e-02,\n",
       "       -2.88354349e-03, -7.42409441e-03, -1.23997215e-02,  2.57254390e-02,\n",
       "       -5.06659997e-04, -6.55909055e-02, -3.13330619e-02, -1.29132732e-03,\n",
       "        4.96549612e-03, -1.58023700e-02,  1.08368739e-02,  2.77417288e-02,\n",
       "       -6.66031184e-03, -2.10814169e-02])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 3 corresponds to interest rate\n",
    "np.cov(dataset.test, rowvar=False)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "unsigned-ethernet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41229742,  0.22918329, -0.00364809,  1.        , -0.6020109 ,\n",
       "        0.18871902,  0.40567998,  0.27323537, -0.08036643, -0.52264594,\n",
       "       -0.1029316 ,  0.33602246, -0.03437017, -0.61868378, -0.37469486,\n",
       "       -0.07965441,  0.10621315, -0.19586893,  0.15949498,  0.20178872,\n",
       "       -0.07910542, -0.15895817])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(dataset.test, rowvar=False)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-lesbian",
   "metadata": {},
   "source": [
    "We see that index 4 (credit score) and index 13 (rate subvention) are somewhat inversely correlated with interest rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-legend",
   "metadata": {},
   "source": [
    "# Findings and Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-daughter",
   "metadata": {},
   "source": [
    "### Finding 1: High precision and accuracy can be achieved with auto loan ABS data\n",
    "\n",
    "Auto loan default can be predicted using the data provided in asset backed securities. We have found a neural network archiecture that predicts the probability of default with 93% precision and 80% accuracy, but only 66% recall. \n",
    "\n",
    "### Finding 2: Lower precision, but higher accuracy and recall can be found with logistic regression opposed to a multi-layer perceptron\n",
    "\n",
    "Logistic regression performed with 86% precision and 83% accuracy as well as 80% recall. Logistic regression had better recall than the neural network, for relatively similar precision. More information on how this model will be applied in practice is needed to properly assess to what extent we should prioritize precision over recall.\n",
    "\n",
    "### Finding 3: Anchor explanations are similar regardless of which of the two models are used\n",
    "\n",
    "The two models we assessed made predictions for very similar reasons. Most of the explanations for the two models came from a single distinguishing factor: interest rate. More often than not, having an interest rate that is less than 18% of the maximum rate observed in the training set was enough to predict that an individual was not likely to default.\n",
    "\n",
    "\n",
    "### Finding 4: There is evidence that anchor explanations differ from the log odds interpretation from logistic regression\n",
    "\n",
    "The logistic regression coefficients were not aligned with the interpretations provided by anchors. Interest rate was a significant differentiator between the classes for anchors, but for logistic regression, the inverse relationship was observed.\n",
    "\n",
    "### Limitations and Next Steps\n",
    "\n",
    "* In the future, different model types can be explored that might be more applicable to this problem such as XGBoost.\n",
    "* To improve interpretability of the explanations, we should take the inverse of the min-max normalization to return the values to their real values\n",
    "* To verify the importance of features to the logistic regression model, we should display the full output of the coefficients with their p-values\n",
    "* The anchors data loader performs class balancing before the train test split. This means that the data tested on is properly balanced as well, which would be unlikely to occur when this model assesses future data. \n",
    "* The anchors data loader performs a split of the test set into two parts: test and validation. This means that the original 20% that is reserved is further split into 10% test and 10% validation. This results in less confidence in the results of the test. In this analysis, I addressed this issue by removing that split in my local version of the anchors package. A future pull request on the repository could be done to make this feature optional in the data loader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-layout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
