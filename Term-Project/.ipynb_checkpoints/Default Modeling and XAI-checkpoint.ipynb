{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "illegal-maldives",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expensive-trail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalLoanAmount</th>\n",
       "      <th>originalLoanTerm</th>\n",
       "      <th>Scheduled Payment Amount</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>creditScore</th>\n",
       "      <th>incomeVerifiedIndicator</th>\n",
       "      <th>usedIndicator</th>\n",
       "      <th>underwritingIndicator</th>\n",
       "      <th>gracePeriodNumber</th>\n",
       "      <th>vehicleValueAmount</th>\n",
       "      <th>...</th>\n",
       "      <th>Not stated, Not Verified Employment</th>\n",
       "      <th>Stated, Not Verified Employment</th>\n",
       "      <th>Stated, Verified Employment</th>\n",
       "      <th>Car</th>\n",
       "      <th>Truck</th>\n",
       "      <th>SUV</th>\n",
       "      <th>Motorcycle</th>\n",
       "      <th>Other Vehicle</th>\n",
       "      <th>Unknown Vehicle</th>\n",
       "      <th>Defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13572.08</td>\n",
       "      <td>69</td>\n",
       "      <td>238.996622</td>\n",
       "      <td>0.06923</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13572.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10949.58</td>\n",
       "      <td>72</td>\n",
       "      <td>186.332638</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12849.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17208.65</td>\n",
       "      <td>69</td>\n",
       "      <td>357.964206</td>\n",
       "      <td>0.13283</td>\n",
       "      <td>627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17208.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25811.33</td>\n",
       "      <td>72</td>\n",
       "      <td>444.408326</td>\n",
       "      <td>0.07350</td>\n",
       "      <td>734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22586.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16226.09</td>\n",
       "      <td>72</td>\n",
       "      <td>312.994913</td>\n",
       "      <td>0.11497</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15431.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   originalLoanAmount  originalLoanTerm  Scheduled Payment Amount  \\\n",
       "0            13572.08                69                238.996622   \n",
       "1            10949.58                72                186.332638   \n",
       "2            17208.65                69                357.964206   \n",
       "3            25811.33                72                444.408326   \n",
       "4            16226.09                72                312.994913   \n",
       "\n",
       "   interestRate  creditScore  incomeVerifiedIndicator  usedIndicator  \\\n",
       "0       0.06923          799                        1              1   \n",
       "1       0.06934          735                        1              1   \n",
       "2       0.13283          627                        1              1   \n",
       "3       0.07350          734                        1              1   \n",
       "4       0.11497          670                        1              1   \n",
       "\n",
       "   underwritingIndicator  gracePeriodNumber  vehicleValueAmount  ...  \\\n",
       "0                    1.0                  0            13572.08  ...   \n",
       "1                    1.0                  0            12849.58  ...   \n",
       "2                    1.0                  0            17208.65  ...   \n",
       "3                    1.0                  0            22586.33  ...   \n",
       "4                    1.0                  0            15431.09  ...   \n",
       "\n",
       "   Not stated, Not Verified Employment  Stated, Not Verified Employment  \\\n",
       "0                                    0                                1   \n",
       "1                                    0                                1   \n",
       "2                                    0                                1   \n",
       "3                                    0                                1   \n",
       "4                                    0                                1   \n",
       "\n",
       "   Stated, Verified Employment  Car  Truck  SUV  Motorcycle  Other Vehicle  \\\n",
       "0                            0    1      0    0           0              0   \n",
       "1                            0    1      0    0           0              0   \n",
       "2                            0    1      0    0           0              0   \n",
       "3                            0    1      0    0           0              0   \n",
       "4                            0    1      0    0           0              0   \n",
       "\n",
       "   Unknown Vehicle  Defaulted  \n",
       "0                0          0  \n",
       "1                0          0  \n",
       "2                0          0  \n",
       "3                0          0  \n",
       "4                0          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-youth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_csv_dataset(data, target_idx, delimiter=',', feature_names=None, \n",
    "                 categorical_features=None,features_to_use=None, \n",
    "                 feature_transformations=None,discretize=False, \n",
    "                 balance=False, fill_na='-1', filter_fn=None, skip_first=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "several-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originalLoanAmount</th>\n",
       "      <th>originalLoanTerm</th>\n",
       "      <th>Scheduled Payment Amount</th>\n",
       "      <th>interestRate</th>\n",
       "      <th>creditScore</th>\n",
       "      <th>incomeVerifiedIndicator</th>\n",
       "      <th>usedIndicator</th>\n",
       "      <th>underwritingIndicator</th>\n",
       "      <th>gracePeriodNumber</th>\n",
       "      <th>vehicleValueAmount</th>\n",
       "      <th>...</th>\n",
       "      <th>rateSubvention</th>\n",
       "      <th>cashRebateSubvention</th>\n",
       "      <th>otherSubvention</th>\n",
       "      <th>Not stated, Not Verified Employment</th>\n",
       "      <th>Stated, Not Verified Employment</th>\n",
       "      <th>Stated, Verified Employment</th>\n",
       "      <th>Car</th>\n",
       "      <th>Truck</th>\n",
       "      <th>SUV</th>\n",
       "      <th>Defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13572.08</td>\n",
       "      <td>69</td>\n",
       "      <td>238.996622</td>\n",
       "      <td>0.06923</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13572.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10949.58</td>\n",
       "      <td>72</td>\n",
       "      <td>186.332638</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12849.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17208.65</td>\n",
       "      <td>69</td>\n",
       "      <td>357.964206</td>\n",
       "      <td>0.13283</td>\n",
       "      <td>627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17208.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25811.33</td>\n",
       "      <td>72</td>\n",
       "      <td>444.408326</td>\n",
       "      <td>0.07350</td>\n",
       "      <td>734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22586.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16226.09</td>\n",
       "      <td>72</td>\n",
       "      <td>312.994913</td>\n",
       "      <td>0.11497</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15431.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   originalLoanAmount  originalLoanTerm  Scheduled Payment Amount  \\\n",
       "0            13572.08                69                238.996622   \n",
       "1            10949.58                72                186.332638   \n",
       "2            17208.65                69                357.964206   \n",
       "3            25811.33                72                444.408326   \n",
       "4            16226.09                72                312.994913   \n",
       "\n",
       "   interestRate  creditScore  incomeVerifiedIndicator  usedIndicator  \\\n",
       "0       0.06923          799                        1              1   \n",
       "1       0.06934          735                        1              1   \n",
       "2       0.13283          627                        1              1   \n",
       "3       0.07350          734                        1              1   \n",
       "4       0.11497          670                        1              1   \n",
       "\n",
       "   underwritingIndicator  gracePeriodNumber  vehicleValueAmount  ...  \\\n",
       "0                    1.0                  0            13572.08  ...   \n",
       "1                    1.0                  0            12849.58  ...   \n",
       "2                    1.0                  0            17208.65  ...   \n",
       "3                    1.0                  0            22586.33  ...   \n",
       "4                    1.0                  0            15431.09  ...   \n",
       "\n",
       "   rateSubvention  cashRebateSubvention  otherSubvention  \\\n",
       "0               0                     0                0   \n",
       "1               0                     0                0   \n",
       "2               0                     0                0   \n",
       "3               0                     0                0   \n",
       "4               0                     0                0   \n",
       "\n",
       "   Not stated, Not Verified Employment  Stated, Not Verified Employment  \\\n",
       "0                                    0                                1   \n",
       "1                                    0                                1   \n",
       "2                                    0                                1   \n",
       "3                                    0                                1   \n",
       "4                                    0                                1   \n",
       "\n",
       "   Stated, Verified Employment  Car  Truck  SUV  Defaulted  \n",
       "0                            0    1      0    0          0  \n",
       "1                            0    1      0    0          0  \n",
       "2                            0    1      0    0          0  \n",
       "3                            0    1      0    0          0  \n",
       "4                            0    1      0    0          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "explicit-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=400)\n",
    "\n",
    "df_majority = train[train.iloc[:,22]==0]\n",
    "df_minority = train[train.iloc[:,22]==1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples=2000000,\n",
    "                                 random_state=400)\n",
    "#Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=1000000,\n",
    "                                 random_state=400)\n",
    "# Combine minority class with downsampled majority class\n",
    "train = pd.concat([df_majority_downsampled, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compact-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.9950000e+03 6.0000000e+01 1.5452858e+02 5.9900001e-02 7.0900000e+02\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.9475000e+04\n",
      " 1.0000000e+00 7.4000001e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00] [0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train.loc[:, df.columns != 'Defaulted'].to_numpy()\n",
    "y_train = train['Defaulted'].to_numpy()\n",
    "X_test = test.loc[:, df.columns != 'Defaulted'].to_numpy()\n",
    "y_test = test['Defaulted'].to_numpy()\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "y_train = y_train[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "\n",
    "# free up memory\n",
    "del df, train, test\n",
    "\n",
    "print(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sufficient-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize training data using min-max normalization and test data using normalization from training set\n",
    "scaler = MinMaxScaler() \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-contest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "toxic-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#X_train = torch.from_numpy(X_train).to(device)\n",
    "#y_train = torch.from_numpy(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modern-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network module that can accept params we will use in our grid search\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# modules: list of (nn activation funcs or layers) see https://pytorch.org/docs/stable/nn.html\n",
    "# modules must retain proper input and output shape sequentially\n",
    "class NetModule(nn.Module):\n",
    "    def __init__(self, net_modules):\n",
    "        super(NetModule, self).__init__()\n",
    "        self.net_modules = nn.Sequential(*net_modules)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net_modules(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "specific-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set internal dimensions\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1 # binary classification, default or no default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "failing-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "included_modules = []\n",
    "\n",
    "# Search Sigmoid activation with different neurons in hidden layer\n",
    "included_modules.append([nn.Linear(input_dim, 50),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(50, output_dim)\n",
    "                          ])\n",
    "\n",
    "# Search Sigmoid activation with different neurons in hidden layer\n",
    "included_modules.append([nn.Linear(input_dim, 15),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(15, output_dim)\n",
    "                          ])\n",
    "\n",
    "# Number of architectures\n",
    "print(len(included_modules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "improved-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Create sklearn scorer for use in architecture search\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "early_stop = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informative-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize skorch NN classifier with default params\n",
    "net = NeuralNetClassifier(\n",
    "    NetModule,\n",
    "    criterion= nn.BCEWithLogitsLoss(),\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__momentum=0.95,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size = len(X_train), \n",
    "    callbacks=[early_stop],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "peripheral-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV 1/2; 1/2] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7492\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.6434\u001b[0m  15.1371\n",
      "      2        \u001b[36m0.6434\u001b[0m       0.6667        0.6612  15.5740\n",
      "      3        0.6612       0.6667        0.7342  15.4375\n",
      "      4        0.7341       0.6667        0.7259  15.4288\n",
      "      5        0.7259       0.6667        0.6505  15.5920\n",
      "      6        0.6505       0.6667        \u001b[35m0.6373\u001b[0m  15.5220\n",
      "      7        \u001b[36m0.6373\u001b[0m       0.3333        0.7074  15.3506\n",
      "      8        0.7074       0.4812        0.6945  15.5529\n",
      "      9        0.6945       0.6667        \u001b[35m0.6255\u001b[0m  15.5970\n",
      "     10        \u001b[36m0.6255\u001b[0m       0.6667        0.6396  15.5735\n",
      "     11        0.6396       0.6667        0.6844  15.4160\n",
      "     12        0.6843       0.6667        0.6724  15.6060\n",
      "     13        0.6723       0.6667        \u001b[35m0.6203\u001b[0m  15.5730\n",
      "     14        \u001b[36m0.6203\u001b[0m       0.6667        \u001b[35m0.6142\u001b[0m  15.4940\n",
      "     15        \u001b[36m0.6142\u001b[0m       \u001b[32m0.6940\u001b[0m        0.6559  15.4470\n",
      "     16        0.6559       \u001b[32m0.7328\u001b[0m        0.6448  15.4765\n",
      "     17        0.6448       0.6667        \u001b[35m0.5981\u001b[0m  15.5230\n",
      "     18        \u001b[36m0.5980\u001b[0m       0.6667        0.6006  15.4070\n",
      "     19        0.6006       0.6667        0.6272  15.5290\n",
      "     20        0.6271       0.6667        0.6195  15.4691\n",
      "     21        0.6194       0.6667        \u001b[35m0.5830\u001b[0m  15.6566\n",
      "     22        \u001b[36m0.5830\u001b[0m       0.6667        \u001b[35m0.5714\u001b[0m  15.6066\n",
      "     23        \u001b[36m0.5714\u001b[0m       0.7235        0.5935  15.4180\n",
      "     24        0.5935       0.7327        0.5906  15.6316\n",
      "     25        0.5906       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5573\u001b[0m  16.4517\n",
      "     26        \u001b[36m0.5572\u001b[0m       0.6667        \u001b[35m0.5463\u001b[0m  16.3120\n",
      "     27        \u001b[36m0.5462\u001b[0m       0.6667        0.5597  15.8940\n",
      "     28        0.5595       0.6667        0.5590  15.8470\n",
      "     29        0.5588       0.6667        \u001b[35m0.5353\u001b[0m  15.6010\n",
      "     30        \u001b[36m0.5351\u001b[0m       0.7349        \u001b[35m0.5179\u001b[0m  15.4320\n",
      "     31        \u001b[36m0.5177\u001b[0m       0.7256        0.5251  15.6460\n",
      "     32        0.5250       0.7345        0.5304  15.8231\n",
      "     33        0.5303       0.7331        \u001b[35m0.5130\u001b[0m  15.6140\n",
      "     34        \u001b[36m0.5129\u001b[0m       0.7342        \u001b[35m0.4951\u001b[0m  15.6126\n",
      "     35        \u001b[36m0.4949\u001b[0m       0.7302        0.4963  15.6480\n",
      "     36        0.4959       0.7114        0.5022  15.5820\n",
      "     37        0.5017       0.7249        \u001b[35m0.4943\u001b[0m  15.6230\n",
      "     38        \u001b[36m0.4937\u001b[0m       \u001b[32m0.7386\u001b[0m        \u001b[35m0.4783\u001b[0m  15.6530\n",
      "     39        \u001b[36m0.4778\u001b[0m       \u001b[32m0.7456\u001b[0m        \u001b[35m0.4727\u001b[0m  15.6570\n",
      "     40        \u001b[36m0.4723\u001b[0m       \u001b[32m0.7475\u001b[0m        0.4781  15.6171\n",
      "     41        0.4778       \u001b[32m0.7477\u001b[0m        0.4771  15.7283\n",
      "     42        0.4768       \u001b[32m0.7581\u001b[0m        \u001b[35m0.4647\u001b[0m  15.7540\n",
      "     43        \u001b[36m0.4643\u001b[0m       0.7578        \u001b[35m0.4547\u001b[0m  15.6390\n",
      "     44        \u001b[36m0.4541\u001b[0m       0.7506        0.4555  15.7620\n",
      "     45        0.4548       0.7471        0.4575  15.7340\n",
      "     46        0.4567       0.7522        \u001b[35m0.4506\u001b[0m  15.8490\n",
      "     47        \u001b[36m0.4498\u001b[0m       \u001b[32m0.7665\u001b[0m        \u001b[35m0.4393\u001b[0m  15.6166\n",
      "     48        \u001b[36m0.4385\u001b[0m       \u001b[32m0.7851\u001b[0m        \u001b[35m0.4343\u001b[0m  15.6440\n",
      "     49        \u001b[36m0.4336\u001b[0m       \u001b[32m0.7882\u001b[0m        0.4357  15.8372\n",
      "     50        0.4351       \u001b[32m0.7913\u001b[0m        \u001b[35m0.4333\u001b[0m  15.7254\n",
      "     51        \u001b[36m0.4326\u001b[0m       \u001b[32m0.7975\u001b[0m        \u001b[35m0.4239\u001b[0m  16.3460\n",
      "     52        \u001b[36m0.4232\u001b[0m       \u001b[32m0.7978\u001b[0m        \u001b[35m0.4160\u001b[0m  15.7895\n",
      "     53        \u001b[36m0.4151\u001b[0m       0.7884        \u001b[35m0.4148\u001b[0m  15.7130\n",
      "     54        \u001b[36m0.4138\u001b[0m       0.7843        0.4149  15.6275\n",
      "     55        0.4138       0.7900        \u001b[35m0.4096\u001b[0m  15.7456\n",
      "     56        \u001b[36m0.4085\u001b[0m       \u001b[32m0.8041\u001b[0m        \u001b[35m0.4014\u001b[0m  15.6819\n",
      "     57        \u001b[36m0.4004\u001b[0m       \u001b[32m0.8189\u001b[0m        \u001b[35m0.3976\u001b[0m  15.9800\n",
      "     58        \u001b[36m0.3966\u001b[0m       \u001b[32m0.8222\u001b[0m        0.3982  15.8053\n",
      "     59        0.3972       \u001b[32m0.8231\u001b[0m        \u001b[35m0.3967\u001b[0m  15.7641\n",
      "     60        \u001b[36m0.3958\u001b[0m       \u001b[32m0.8247\u001b[0m        \u001b[35m0.3912\u001b[0m  15.6896\n",
      "     61        \u001b[36m0.3902\u001b[0m       0.8233        \u001b[35m0.3868\u001b[0m  15.7620\n",
      "     62        \u001b[36m0.3857\u001b[0m       0.8189        0.3870  15.7999\n",
      "     63        0.3857       0.8157        0.3881  15.8260\n",
      "     64        0.3868       0.8184        \u001b[35m0.3859\u001b[0m  15.7407\n",
      "     65        \u001b[36m0.3845\u001b[0m       0.8239        \u001b[35m0.3819\u001b[0m  15.7810\n",
      "     66        \u001b[36m0.3806\u001b[0m       \u001b[32m0.8263\u001b[0m        \u001b[35m0.3807\u001b[0m  15.8610\n",
      "     67        \u001b[36m0.3794\u001b[0m       0.8262        0.3823  15.7950\n",
      "     68        0.3810       0.8258        0.3826  15.8052\n",
      "     69        0.3813       \u001b[32m0.8265\u001b[0m        \u001b[35m0.3804\u001b[0m  15.7371\n",
      "     70        \u001b[36m0.3790\u001b[0m       0.8261        \u001b[35m0.3785\u001b[0m  15.8554\n",
      "     71        \u001b[36m0.3771\u001b[0m       0.8239        0.3793  15.7152\n",
      "     72        0.3778       0.8211        0.3808  15.7460\n",
      "     73        0.3792       0.8218        0.3803  15.7440\n",
      "     74        0.3786       0.8246        \u001b[35m0.3784\u001b[0m  16.2800\n",
      "     75        \u001b[36m0.3767\u001b[0m       0.8264        \u001b[35m0.3777\u001b[0m  15.8587\n",
      "     76        \u001b[36m0.3761\u001b[0m       0.8263        0.3788  15.7020\n",
      "     77        0.3772       0.8262        0.3796  15.8241\n",
      "     78        0.3780       0.8265        0.3787  15.7982\n",
      "     79        0.3771       0.8265        \u001b[35m0.3775\u001b[0m  15.7637\n",
      "     80        \u001b[36m0.3758\u001b[0m       0.8255        0.3777  16.0280\n",
      "     81        0.3760       0.8231        0.3788  15.9540\n",
      "     82        0.3770       0.8228        0.3791  15.8410\n",
      "     83        0.3773       0.8243        0.3782  15.6946\n",
      "     84        0.3764       0.8260        \u001b[35m0.3775\u001b[0m  15.7650\n",
      "     85        \u001b[36m0.3757\u001b[0m       \u001b[32m0.8266\u001b[0m        0.3779  15.7816\n",
      "     86        0.3761       \u001b[32m0.8268\u001b[0m        0.3786  15.8961\n",
      "     87        0.3769       \u001b[32m0.8269\u001b[0m        0.3785  15.7991\n",
      "     88        0.3768       0.8266        0.3777  15.8880\n",
      "     89        0.3759       0.8257        \u001b[35m0.3773\u001b[0m  16.0250\n",
      "     90        \u001b[36m0.3755\u001b[0m       0.8245        0.3777  15.9080\n",
      "     91        0.3759       0.8240        0.3781  15.8170\n",
      "     92        0.3763       0.8243        0.3777  15.8470\n",
      "     93        0.3759       0.8252        \u001b[35m0.3769\u001b[0m  15.8890\n",
      "     94        \u001b[36m0.3751\u001b[0m       0.8269        \u001b[35m0.3764\u001b[0m  15.8720\n",
      "     95        \u001b[36m0.3747\u001b[0m       \u001b[32m0.8274\u001b[0m        0.3766  16.1250\n",
      "     96        0.3749       0.8273        0.3766  17.7942\n",
      "     97        0.3749       \u001b[32m0.8277\u001b[0m        \u001b[35m0.3760\u001b[0m  16.2691\n",
      "     98        \u001b[36m0.3744\u001b[0m       \u001b[32m0.8277\u001b[0m        \u001b[35m0.3753\u001b[0m  15.8670\n",
      "     99        \u001b[36m0.3737\u001b[0m       0.8275        \u001b[35m0.3750\u001b[0m  16.2311\n",
      "    100        \u001b[36m0.3733\u001b[0m       0.8268        0.3751  15.9861\n",
      "[CV 1/2; 1/2] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]; total time=26.6min\n",
      "[CV 2/2; 1/2] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7492\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.6434\u001b[0m  15.8120\n",
      "      2        \u001b[36m0.6434\u001b[0m       0.6667        0.6612  15.7950\n",
      "      3        0.6612       0.6667        0.7342  15.9990\n",
      "      4        0.7341       0.6667        0.7259  15.8860\n",
      "      5        0.7259       0.6667        0.6505  15.9980\n",
      "      6        0.6505       0.6667        \u001b[35m0.6373\u001b[0m  15.8091\n",
      "      7        \u001b[36m0.6373\u001b[0m       0.3333        0.7074  15.8806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        0.7074       0.4799        0.6945  16.1700\n",
      "      9        0.6945       0.6667        \u001b[35m0.6256\u001b[0m  16.0700\n",
      "     10        \u001b[36m0.6255\u001b[0m       0.6667        0.6396  16.0008\n",
      "     11        0.6395       0.6667        0.6844  15.8420\n",
      "     12        0.6843       0.6667        0.6724  15.8970\n",
      "     13        0.6723       0.6667        \u001b[35m0.6204\u001b[0m  15.8697\n",
      "     14        \u001b[36m0.6203\u001b[0m       0.6667        \u001b[35m0.6142\u001b[0m  16.1530\n",
      "     15        \u001b[36m0.6141\u001b[0m       \u001b[32m0.6945\u001b[0m        0.6560  15.8432\n",
      "     16        0.6558       \u001b[32m0.7335\u001b[0m        0.6449  15.8330\n",
      "     17        0.6447       0.6667        \u001b[35m0.5981\u001b[0m  15.8342\n",
      "     18        \u001b[36m0.5979\u001b[0m       0.6667        0.6006  15.8940\n",
      "     19        0.6004       0.6667        0.6272  15.9640\n",
      "     20        0.6270       0.6667        0.6195  15.7210\n",
      "     21        0.6193       0.6667        \u001b[35m0.5831\u001b[0m  15.9610\n",
      "     22        \u001b[36m0.5828\u001b[0m       0.6667        \u001b[35m0.5715\u001b[0m  15.8566\n",
      "     23        \u001b[36m0.5712\u001b[0m       0.7243        0.5937  15.9925\n",
      "     24        0.5934       0.7333        0.5907  15.8680\n",
      "     25        0.5904       \u001b[32m0.7336\u001b[0m        \u001b[35m0.5574\u001b[0m  16.5190\n",
      "     26        \u001b[36m0.5570\u001b[0m       0.6667        \u001b[35m0.5464\u001b[0m  16.0157\n",
      "     27        \u001b[36m0.5460\u001b[0m       0.6667        0.5597  15.7660\n",
      "     28        0.5593       0.6667        0.5590  15.8881\n",
      "     29        0.5586       0.6667        \u001b[35m0.5354\u001b[0m  15.8420\n",
      "     30        \u001b[36m0.5349\u001b[0m       0.7334        \u001b[35m0.5180\u001b[0m  15.8955\n",
      "     31        \u001b[36m0.5175\u001b[0m       0.7255        0.5252  15.9779\n",
      "     32        0.5247       \u001b[32m0.7350\u001b[0m        0.5306  16.1551\n",
      "     33        0.5301       0.7329        \u001b[35m0.5133\u001b[0m  15.8350\n",
      "     34        \u001b[36m0.5127\u001b[0m       0.7339        \u001b[35m0.4953\u001b[0m  15.9240\n",
      "     35        \u001b[36m0.4947\u001b[0m       0.7297        0.4965  15.8790\n",
      "     36        0.4957       0.7118        0.5023  15.9047\n",
      "     37        0.5015       0.7250        \u001b[35m0.4944\u001b[0m  16.3045\n",
      "     38        \u001b[36m0.4936\u001b[0m       \u001b[32m0.7382\u001b[0m        \u001b[35m0.4785\u001b[0m  15.9891\n",
      "     39        \u001b[36m0.4777\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m0.4730\u001b[0m  15.9650\n",
      "     40        \u001b[36m0.4722\u001b[0m       \u001b[32m0.7476\u001b[0m        0.4785  16.1020\n",
      "     41        0.4777       0.7475        0.4776  15.9590\n",
      "     42        0.4768       \u001b[32m0.7585\u001b[0m        \u001b[35m0.4652\u001b[0m  15.8190\n",
      "     43        \u001b[36m0.4643\u001b[0m       0.7568        \u001b[35m0.4551\u001b[0m  15.9421\n",
      "     44        \u001b[36m0.4542\u001b[0m       0.7501        0.4558  15.9571\n",
      "     45        0.4548       0.7466        0.4578  16.0202\n",
      "     46        0.4567       0.7516        \u001b[35m0.4511\u001b[0m  15.9220\n",
      "     47        \u001b[36m0.4500\u001b[0m       \u001b[32m0.7657\u001b[0m        \u001b[35m0.4398\u001b[0m  15.8390\n",
      "     48        \u001b[36m0.4387\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m0.4348\u001b[0m  15.9431\n",
      "     49        \u001b[36m0.4338\u001b[0m       \u001b[32m0.7873\u001b[0m        0.4362  15.9400\n",
      "     50        0.4352       \u001b[32m0.7899\u001b[0m        \u001b[35m0.4339\u001b[0m  15.9126\n",
      "     51        \u001b[36m0.4329\u001b[0m       \u001b[32m0.7964\u001b[0m        \u001b[35m0.4246\u001b[0m  15.8570\n",
      "     52        \u001b[36m0.4235\u001b[0m       \u001b[32m0.7974\u001b[0m        \u001b[35m0.4165\u001b[0m  15.9280\n",
      "     53        \u001b[36m0.4154\u001b[0m       0.7880        \u001b[35m0.4152\u001b[0m  15.9179\n",
      "     54        \u001b[36m0.4140\u001b[0m       0.7841        0.4153  16.0440\n",
      "     55        0.4141       0.7888        \u001b[35m0.4101\u001b[0m  16.3780\n",
      "     56        \u001b[36m0.4089\u001b[0m       \u001b[32m0.8024\u001b[0m        \u001b[35m0.4019\u001b[0m  15.7697\n",
      "     57        \u001b[36m0.4008\u001b[0m       \u001b[32m0.8171\u001b[0m        \u001b[35m0.3981\u001b[0m  15.8440\n",
      "     58        \u001b[36m0.3970\u001b[0m       \u001b[32m0.8208\u001b[0m        0.3986  15.8161\n",
      "     59        0.3976       \u001b[32m0.8225\u001b[0m        \u001b[35m0.3972\u001b[0m  15.9420\n",
      "     60        \u001b[36m0.3962\u001b[0m       \u001b[32m0.8238\u001b[0m        \u001b[35m0.3917\u001b[0m  15.8470\n",
      "     61        \u001b[36m0.3907\u001b[0m       0.8227        \u001b[35m0.3872\u001b[0m  15.8947\n",
      "     62        \u001b[36m0.3862\u001b[0m       0.8186        0.3872  15.8256\n",
      "     63        \u001b[36m0.3861\u001b[0m       0.8155        0.3883  15.8921\n",
      "     64        0.3872       0.8184        \u001b[35m0.3861\u001b[0m  15.8860\n",
      "     65        \u001b[36m0.3851\u001b[0m       0.8230        \u001b[35m0.3822\u001b[0m  15.8120\n",
      "     66        \u001b[36m0.3812\u001b[0m       \u001b[32m0.8258\u001b[0m        \u001b[35m0.3809\u001b[0m  16.2618\n",
      "     67        \u001b[36m0.3800\u001b[0m       0.8254        0.3825  16.0010\n",
      "     68        0.3815       0.8252        0.3828  15.9603\n",
      "     69        0.3819       0.8256        \u001b[35m0.3806\u001b[0m  15.8116\n",
      "     70        \u001b[36m0.3797\u001b[0m       0.8252        \u001b[35m0.3786\u001b[0m  15.7640\n",
      "     71        \u001b[36m0.3777\u001b[0m       0.8232        0.3793  15.7780\n",
      "     72        0.3784       0.8211        0.3807  16.1322\n",
      "     73        0.3798       0.8218        0.3803  16.0076\n",
      "     74        0.3793       0.8243        \u001b[35m0.3784\u001b[0m  15.6796\n",
      "     75        \u001b[36m0.3775\u001b[0m       0.8256        \u001b[35m0.3777\u001b[0m  15.8820\n",
      "     76        \u001b[36m0.3768\u001b[0m       0.8255        0.3788  15.8680\n",
      "     77        0.3779       0.8256        0.3795  15.9554\n",
      "     78        0.3787       0.8257        0.3787  15.7476\n",
      "     79        0.3778       \u001b[32m0.8259\u001b[0m        \u001b[35m0.3775\u001b[0m  15.8231\n",
      "     80        \u001b[36m0.3765\u001b[0m       0.8255        0.3776  15.8294\n",
      "     81        0.3766       0.8233        0.3786  15.7780\n",
      "     82        0.3777       0.8227        0.3789  15.9210\n",
      "     83        0.3779       0.8242        0.3780  15.8800\n",
      "     84        0.3771       \u001b[32m0.8261\u001b[0m        \u001b[35m0.3773\u001b[0m  15.9817\n",
      "     85        \u001b[36m0.3763\u001b[0m       \u001b[32m0.8263\u001b[0m        0.3777  15.8810\n",
      "     86        0.3767       \u001b[32m0.8267\u001b[0m        0.3785  15.9411\n",
      "     87        0.3775       \u001b[32m0.8268\u001b[0m        0.3784  15.9332\n",
      "     88        0.3774       0.8266        0.3776  15.7810\n",
      "     89        0.3766       0.8251        \u001b[35m0.3772\u001b[0m  15.9870\n",
      "     90        \u001b[36m0.3762\u001b[0m       0.8244        0.3776  15.9901\n",
      "     91        0.3765       0.8240        0.3780  15.8796\n",
      "     92        0.3769       0.8244        0.3776  15.8090\n",
      "     93        0.3766       0.8248        \u001b[35m0.3768\u001b[0m  15.9310\n",
      "     94        \u001b[36m0.3758\u001b[0m       0.8262        \u001b[35m0.3764\u001b[0m  15.8890\n",
      "     95        \u001b[36m0.3754\u001b[0m       \u001b[32m0.8269\u001b[0m        0.3766  16.2401\n",
      "     96        0.3756       \u001b[32m0.8271\u001b[0m        0.3766  15.9290\n",
      "     97        0.3756       0.8271        \u001b[35m0.3761\u001b[0m  15.8696\n",
      "     98        \u001b[36m0.3751\u001b[0m       0.8270        \u001b[35m0.3754\u001b[0m  15.8935\n",
      "     99        \u001b[36m0.3744\u001b[0m       0.8270        \u001b[35m0.3751\u001b[0m  15.8508\n",
      "    100        \u001b[36m0.3740\u001b[0m       0.8262        0.3752  15.7960\n",
      "[CV 2/2; 1/2] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]; total time=26.9min\n",
      "[CV 1/2; 2/2] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=15, bias=True), Sigmoid(), Linear(in_features=15, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7884\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m0.7198\u001b[0m  15.7630\n",
      "      2        \u001b[36m0.7198\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.6511\u001b[0m  15.8407\n",
      "      3        \u001b[36m0.6510\u001b[0m       0.6667        \u001b[35m0.6417\u001b[0m  15.7400\n",
      "      4        \u001b[36m0.6417\u001b[0m       0.6667        0.6834  15.6726\n",
      "      5        0.6834       0.6667        0.7300  15.7040\n",
      "      6        0.7300       0.6667        0.7473  15.7780\n",
      "      7        0.7473       0.6667        0.7264  15.6800\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 2/2] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=15, bias=True), Sigmoid(), Linear(in_features=15, out_features=1, bias=True)]; total time= 2.4min\n",
      "[CV 2/2; 2/2] START lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=15, bias=True), Sigmoid(), Linear(in_features=15, out_features=1, bias=True)]\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7884\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m0.7198\u001b[0m  15.3780\n",
      "      2        \u001b[36m0.7198\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.6510\u001b[0m  15.8920\n",
      "      3        \u001b[36m0.6511\u001b[0m       0.6667        \u001b[35m0.6417\u001b[0m  15.9465\n",
      "      4        \u001b[36m0.6417\u001b[0m       0.6667        0.6834  15.6990\n",
      "      5        0.6834       0.6667        0.7300  15.7845\n",
      "      6        0.7301       0.6667        0.7472  15.7690\n",
      "      7        0.7473       0.6667        0.7264  15.8531\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 2/2] END lr=0.2, max_epochs=100, module__net_modules=[Linear(in_features=22, out_features=15, bias=True), Sigmoid(), Linear(in_features=15, out_features=1, bias=True)]; total time= 2.4min\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7492\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.6434\u001b[0m  33.9220\n",
      "      2        \u001b[36m0.6434\u001b[0m       0.6667        0.6612  34.8880\n",
      "      3        0.6612       0.6667        0.7341  34.5750\n",
      "      4        0.7341       0.6667        0.7258  34.9045\n",
      "      5        0.7259       0.6667        0.6505  35.0051\n",
      "      6        0.6505       0.6667        \u001b[35m0.6373\u001b[0m  34.9042\n",
      "      7        \u001b[36m0.6373\u001b[0m       0.3333        0.7074  34.9622\n",
      "      8        0.7074       0.4805        0.6945  36.2503\n",
      "      9        0.6945       0.6667        \u001b[35m0.6255\u001b[0m  35.2100\n",
      "     10        \u001b[36m0.6255\u001b[0m       0.6667        0.6396  35.1566\n",
      "     11        0.6396       0.6667        0.6843  35.0880\n",
      "     12        0.6843       0.6667        0.6723  35.3508\n",
      "     13        0.6723       0.6667        \u001b[35m0.6203\u001b[0m  36.6972\n",
      "     14        \u001b[36m0.6203\u001b[0m       0.6667        \u001b[35m0.6142\u001b[0m  35.4156\n",
      "     15        \u001b[36m0.6142\u001b[0m       \u001b[32m0.6942\u001b[0m        0.6560  35.5588\n",
      "     16        0.6559       \u001b[32m0.7335\u001b[0m        0.6449  35.4095\n",
      "     17        0.6448       0.6667        \u001b[35m0.5981\u001b[0m  35.4071\n",
      "     18        \u001b[36m0.5980\u001b[0m       0.6667        0.6005  35.6990\n",
      "     19        0.6005       0.6667        0.6271  36.0010\n",
      "     20        0.6271       0.6667        0.6194  35.6806\n",
      "     21        0.6193       0.6667        \u001b[35m0.5830\u001b[0m  36.0334\n",
      "     22        \u001b[36m0.5829\u001b[0m       0.6667        \u001b[35m0.5714\u001b[0m  35.8750\n",
      "     23        \u001b[36m0.5713\u001b[0m       0.7240        0.5936  35.8560\n",
      "     24        0.5935       \u001b[32m0.7335\u001b[0m        0.5907  35.8200\n",
      "     25        0.5906       \u001b[32m0.7340\u001b[0m        \u001b[35m0.5573\u001b[0m  36.0184\n",
      "     26        \u001b[36m0.5572\u001b[0m       0.6667        \u001b[35m0.5462\u001b[0m  36.1317\n",
      "     27        \u001b[36m0.5462\u001b[0m       0.6667        0.5595  36.2152\n",
      "     28        0.5595       0.6667        0.5588  36.3440\n",
      "     29        0.5587       0.6667        \u001b[35m0.5351\u001b[0m  36.5216\n",
      "     30        \u001b[36m0.5351\u001b[0m       0.7337        \u001b[35m0.5178\u001b[0m  36.4676\n",
      "     31        \u001b[36m0.5177\u001b[0m       0.7256        0.5250  36.5046\n",
      "     32        0.5249       \u001b[32m0.7350\u001b[0m        0.5304  36.6629\n",
      "     33        0.5303       0.7331        \u001b[35m0.5130\u001b[0m  36.5507\n",
      "     34        \u001b[36m0.5129\u001b[0m       0.7341        \u001b[35m0.4949\u001b[0m  37.0130\n",
      "     35        \u001b[36m0.4949\u001b[0m       0.7297        0.4960  36.5586\n",
      "     36        0.4959       0.7114        0.5017  36.1730\n",
      "     37        0.5017       0.7248        \u001b[35m0.4938\u001b[0m  36.3490\n",
      "     38        \u001b[36m0.4938\u001b[0m       \u001b[32m0.7380\u001b[0m        \u001b[35m0.4779\u001b[0m  36.3640\n",
      "     39        \u001b[36m0.4779\u001b[0m       \u001b[32m0.7457\u001b[0m        \u001b[35m0.4724\u001b[0m  37.2987\n",
      "     40        \u001b[36m0.4723\u001b[0m       \u001b[32m0.7479\u001b[0m        0.4780  37.2826\n",
      "     41        0.4778       0.7479        0.4770  41.0848\n",
      "     42        0.4769       \u001b[32m0.7588\u001b[0m        \u001b[35m0.4645\u001b[0m  38.3361\n",
      "     43        \u001b[36m0.4644\u001b[0m       0.7576        \u001b[35m0.4544\u001b[0m  36.8960\n",
      "     44        \u001b[36m0.4542\u001b[0m       0.7501        0.4550  37.2320\n",
      "     45        0.4549       0.7466        0.4570  37.2930\n",
      "     46        0.4568       0.7514        \u001b[35m0.4502\u001b[0m  36.7586\n",
      "     47        \u001b[36m0.4500\u001b[0m       \u001b[32m0.7660\u001b[0m        \u001b[35m0.4389\u001b[0m  38.0956\n",
      "     48        \u001b[36m0.4387\u001b[0m       \u001b[32m0.7852\u001b[0m        \u001b[35m0.4340\u001b[0m  37.8245\n",
      "     49        \u001b[36m0.4338\u001b[0m       \u001b[32m0.7876\u001b[0m        0.4355  37.7845\n",
      "     50        0.4352       \u001b[32m0.7907\u001b[0m        \u001b[35m0.4332\u001b[0m  37.8330\n",
      "     51        \u001b[36m0.4329\u001b[0m       \u001b[32m0.7969\u001b[0m        \u001b[35m0.4238\u001b[0m  37.5530\n",
      "     52        \u001b[36m0.4235\u001b[0m       \u001b[32m0.7975\u001b[0m        \u001b[35m0.4157\u001b[0m  37.9370\n",
      "     53        \u001b[36m0.4153\u001b[0m       0.7881        \u001b[35m0.4145\u001b[0m  38.0230\n",
      "     54        \u001b[36m0.4140\u001b[0m       0.7838        0.4146  37.9120\n",
      "     55        0.4141       0.7894        \u001b[35m0.4093\u001b[0m  38.7920\n",
      "     56        \u001b[36m0.4088\u001b[0m       \u001b[32m0.8032\u001b[0m        \u001b[35m0.4012\u001b[0m  38.1510\n",
      "     57        \u001b[36m0.4007\u001b[0m       \u001b[32m0.8174\u001b[0m        \u001b[35m0.3975\u001b[0m  38.0950\n",
      "     58        \u001b[36m0.3969\u001b[0m       \u001b[32m0.8213\u001b[0m        0.3981  38.4040\n",
      "     59        0.3975       \u001b[32m0.8225\u001b[0m        \u001b[35m0.3967\u001b[0m  38.1330\n",
      "     60        \u001b[36m0.3961\u001b[0m       \u001b[32m0.8239\u001b[0m        \u001b[35m0.3912\u001b[0m  38.7702\n",
      "     61        \u001b[36m0.3906\u001b[0m       0.8228        \u001b[35m0.3867\u001b[0m  38.5260\n",
      "     62        \u001b[36m0.3860\u001b[0m       0.8188        0.3868  38.4461\n",
      "     63        0.3861       0.8157        0.3879  38.7940\n",
      "     64        0.3871       0.8186        \u001b[35m0.3857\u001b[0m  38.5431\n",
      "     65        \u001b[36m0.3849\u001b[0m       0.8232        \u001b[35m0.3818\u001b[0m  38.5631\n",
      "     66        \u001b[36m0.3810\u001b[0m       \u001b[32m0.8259\u001b[0m        \u001b[35m0.3806\u001b[0m  38.6145\n",
      "     67        \u001b[36m0.3798\u001b[0m       0.8255        0.3821  38.2205\n",
      "     68        0.3814       0.8251        0.3825  39.2570\n",
      "     69        0.3817       0.8257        \u001b[35m0.3802\u001b[0m  38.5586\n",
      "     70        \u001b[36m0.3794\u001b[0m       0.8253        \u001b[35m0.3783\u001b[0m  38.6670\n",
      "     71        \u001b[36m0.3775\u001b[0m       0.8232        0.3790  38.6615\n",
      "     72        0.3781       0.8211        0.3804  38.4766\n",
      "     73        0.3796       0.8216        0.3799  39.2225\n",
      "     74        0.3791       0.8241        \u001b[35m0.3780\u001b[0m  39.8051\n",
      "     75        \u001b[36m0.3772\u001b[0m       0.8257        \u001b[35m0.3773\u001b[0m  39.5546\n",
      "     76        \u001b[36m0.3765\u001b[0m       0.8257        0.3784  38.8588\n",
      "     77        0.3777       0.8256        0.3792  38.8042\n",
      "     78        0.3784       0.8259        0.3783  39.1150\n",
      "     79        0.3775       \u001b[32m0.8260\u001b[0m        \u001b[35m0.3770\u001b[0m  38.7830\n",
      "     80        \u001b[36m0.3763\u001b[0m       0.8252        0.3772  38.4760\n",
      "     81        0.3764       0.8232        0.3782  39.3624\n",
      "     82        0.3774       0.8227        0.3785  38.9710\n",
      "     83        0.3777       0.8241        0.3775  38.9825\n",
      "     84        0.3768       0.8260        \u001b[35m0.3768\u001b[0m  38.9780\n",
      "     85        \u001b[36m0.3761\u001b[0m       \u001b[32m0.8264\u001b[0m        0.3772  38.6890\n",
      "     86        0.3765       \u001b[32m0.8267\u001b[0m        0.3779  39.8027\n",
      "     87        0.3773       \u001b[32m0.8267\u001b[0m        0.3778  38.7350\n",
      "     88        0.3772       0.8267        0.3770  38.9203\n",
      "     89        0.3764       0.8256        \u001b[35m0.3766\u001b[0m  39.1087\n",
      "     90        \u001b[36m0.3759\u001b[0m       0.8244        0.3770  38.8728\n",
      "     91        0.3763       0.8241        0.3774  39.1231\n",
      "     92        0.3766       0.8244        0.3770  39.2621\n",
      "     93        0.3763       0.8250        \u001b[35m0.3762\u001b[0m  38.7212\n",
      "     94        \u001b[36m0.3755\u001b[0m       \u001b[32m0.8268\u001b[0m        \u001b[35m0.3758\u001b[0m  39.5150\n",
      "     95        \u001b[36m0.3751\u001b[0m       \u001b[32m0.8271\u001b[0m        0.3760  39.1465\n",
      "     96        0.3753       \u001b[32m0.8272\u001b[0m        0.3760  39.0547\n",
      "     97        0.3753       \u001b[32m0.8273\u001b[0m        \u001b[35m0.3755\u001b[0m  39.1788\n",
      "     98        \u001b[36m0.3748\u001b[0m       \u001b[32m0.8273\u001b[0m        \u001b[35m0.3748\u001b[0m  38.8897\n",
      "     99        \u001b[36m0.3741\u001b[0m       0.8273        \u001b[35m0.3744\u001b[0m  39.2531\n",
      "    100        \u001b[36m0.3737\u001b[0m       0.8265        0.3745  39.0796\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV and output the best performing parameters\n",
    "\n",
    "#parameters to test using gridsearch\n",
    "params = {\n",
    "    'lr': [0.2], \n",
    "    'max_epochs': [100],\n",
    "    #pass parameters to NetModule constructor to set architecture\n",
    "    'module__net_modules': included_modules\n",
    "} \n",
    "\n",
    "# Perform grid search with 2-fold cross validation, will refit model at the end using best params on entire training set\n",
    "gs = GridSearchCV(net, params, refit=True, cv=2, scoring=precision_scorer, verbose=10)\n",
    "\n",
    "start_time = time.time()\n",
    "gs.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "model_output = (elapsed_time, gs) \n",
    "pickle.dump( model_output, open( \"default_model.p\", \"wb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "willing-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Precision: 0.7327292681796795\n",
      "Best Parameters: {'lr': 0.2, 'max_epochs': 100, 'module__net_modules': [Linear(in_features=22, out_features=50, bias=True), Sigmoid(), Linear(in_features=50, out_features=1, bias=True)]}\n"
     ]
    }
   ],
   "source": [
    "elapsed, gs = pickle.load( open( \"default_model.p\", \"rb\" ) )\n",
    "print(\"Best Precision: \" + str(gs.best_score_) + \"\\nBest Parameters: \" + str(gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "searching-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 7259.2 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Time: \" + '{0:.5}'.format(elapsed) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "guided-register",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Test Data: 0.16107069537733767\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.predict(X_test)\n",
    "  \n",
    "print(\"Precision on Test Data: \" + str(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "minus-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8580229833805435\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "working-recorder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x213850bac10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-cliff",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "strategic-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Test Data: 0.16113918762849444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Precision on Test Data: \" + str(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "still-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8562321136973331\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "enhanced-harvest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2139f74e4f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-course",
   "metadata": {},
   "source": [
    "# XAI Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-oriental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reserved-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import utils\n",
    "from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aquatic-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_array_values(array, value_map):\n",
    "    # value map must be { src : target }\n",
    "    ret = array.copy()\n",
    "    for src, target in value_map.items():\n",
    "        ret[ret == src] = target\n",
    "    return ret\n",
    "\n",
    "def replace_binary_values(array, values):\n",
    "    return map_array_values(array, {'0': values[0], '1': values[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "scenic-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_names = {\n",
    "            5: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            6: lambda x: replace_binary_values(x, ['New Vehicle', 'Used Vehicle']),\n",
    "            7: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            10: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            11: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            12: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            13: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            14: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            15: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            16: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            17: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            18: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            19: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            20: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "            21: lambda x: replace_binary_values(x, ['No', 'Yes']),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    " for feature, fun in categorical_names.items():\n",
    "        X_train[:, feature] = fun(X_train[:, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "challenging-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(class_names, feature_names, X_train, categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "accepted-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for outputting a flattened version of neural network predictions for use in explainer\n",
    "def predict_and_flatten(X):\n",
    "    y = gs.predict(X)\n",
    "    y = y.flatten()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "known-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction:  Not Defaulted\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "np.random.seed(1)\n",
    "print('Neural Network Prediction: ', explainer.class_names[int(gs.predict(X_test[0]))])\n",
    "exp = explainer.explain_instance(X_test[idx], predict_and_flatten, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "deluxe-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: interestRate <= 0.13\n",
      "Precision: 1.00\n",
      "Coverage: 0.26\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "official-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction:  Not Defaulted\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Prediction: ', explainer.class_names[int(log_reg.predict(X_test[0].reshape(1, -1)))])\n",
    "exp = explainer.explain_instance(X_test[idx], log_reg.predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "governmental-dakota",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: interestRate <= 0.13\n",
      "Precision: 1.00\n",
      "Coverage: 0.26\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "second-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['originalLoanAmount', 'originalLoanTerm', 'Scheduled Payment Amount',\n",
      "       'interestRate', 'creditScore', 'incomeVerifiedIndicator',\n",
      "       'usedIndicator', 'underwritingIndicator', 'gracePeriodNumber',\n",
      "       'vehicleValueAmount', 'coObligorIndicator', 'paymentToIncomePercentage',\n",
      "       'assetAddedIndicator', 'rateSubvention', 'cashRebateSubvention',\n",
      "       'otherSubvention', 'Not stated, Not Verified Employment',\n",
      "       'Stated, Not Verified Employment', 'Stated, Verified Employment', 'Car',\n",
      "       'Truck', 'SUV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    " print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "federal-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.13\n",
      "Precision: 1.00\n",
      "Coverage: 0.26\n",
      "Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.37\n",
      "Precision: 1.00\n",
      "Coverage: 0.50\n",
      "Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.37\n",
      "Precision: 1.00\n",
      "Coverage: 0.50\n",
      "Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.13\n",
      "Precision: 1.00\n",
      "Coverage: 0.25\n",
      "Neural Network Prediction:  Not Defaulted\n",
      "Anchor: interestRate <= 0.37\n",
      "Precision: 1.00\n",
      "Coverage: 0.50\n",
      "Neural Network Prediction:  Not Defaulted\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-185d766d8256>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Neural Network Prediction: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_and_flatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Anchor: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' AND '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m             **kwargs)\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_names_to_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instance'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mexp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\anchor\\anchor_tabular.py\u001b[0m in \u001b[0;36madd_names_to_exp\u001b[1;34m(self, data_row, hoeffding_exp, mapping)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                     if ('<' in self.categorical_names[f][v]\n\u001b[0m\u001b[0;32m    313\u001b[0m                             or '>' in self.categorical_names[f][v]):\n\u001b[0;32m    314\u001b[0m                         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "exps = []\n",
    "\n",
    "for idx in range(len(X_test)):\n",
    "    print('Neural Network Prediction: ', explainer.class_names[int(gs.predict(X_test[0]))])\n",
    "    exp = explainer.explain_instance(X_test[idx], predict_and_flatten, threshold=0.95)\n",
    "    print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "    print('Precision: %.2f' % exp.precision())\n",
    "    print('Coverage: %.2f' % exp.coverage())\n",
    "    exps.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-martial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
